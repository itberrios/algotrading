{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Models\n",
    "\n",
    "In this notebook, we will explore some Toy Models to perform regression on a few data sets of stock data. We will preprocess the stock data to contain the Times in the form of sines and cosines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from window_generator import WindowGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for python scripts use: \"os.path.dirname(__file__)\" instead of \"os.path.abspath('')\"\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.abspath(''), os.path.pardir)))\n",
    "\n",
    "from data_clean import get_trading_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'..\\data\\raw\\AAPL_15min.csv'\n",
    "df = pd.read_csv(data_path, index_col=0, \n",
    "                 parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "# df = get_trading_times(df)\n",
    "df = df.dropna()\n",
    "\n",
    "# add days, hours, and minutes to the dataset\n",
    "dayofweek = df.index.dayofweek\n",
    "hour = df.index.hour\n",
    "minute = df.index.minute\n",
    "\n",
    "# encode the days, hours, and minutes with sin and cos functions\n",
    "eps = 1e-4 # ensure that encodings don't have NaNs\n",
    "# df['sin_day'] = np.sin(2*np.pi/(dayofweek + eps))\n",
    "# df['cos_day'] = np.cos(2*np.pi/(dayofweek + eps))\n",
    "# df['sin_hour'] = np.sin(2*np.pi/(hour + eps))\n",
    "# df['cos_hour'] = np.cos(2*np.pi/(hour + eps))\n",
    "# df['sin_minute'] = np.sin(2*np.pi/(minute + eps))\n",
    "# df['cos_minute'] = np.cos(2*np.pi/(minute + eps))\n",
    "\n",
    "\n",
    "days_in_week = 7\n",
    "hours_in_day = 24\n",
    "minutes_in_hour = 60\n",
    "\n",
    "df['sin_day'] = np.sin(2*np.pi*dayofweek/days_in_week)\n",
    "df['cos_day'] = np.cos(2*np.pi*dayofweek/days_in_week)\n",
    "df['sin_hour'] = np.sin(2*np.pi*hour/hours_in_day)\n",
    "df['cos_hour'] = np.cos(2*np.pi*hour/hours_in_day)\n",
    "df['sin_minute'] = np.sin(2*np.pi*minute/minutes_in_hour)\n",
    "df['cos_minute'] = np.cos(2*np.pi*minute/minutes_in_hour)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add target columns\n",
    "We will add a column for price change at each interval, this will be our regression target variable. We will also add another column that quantifys the magnitude of the price change, this will be out target variable for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_diff'] = df['close'].diff()\n",
    "\n",
    "# thresh = 0.1 # dollars\n",
    "# df['price_change'] = 1 # price stays the same\n",
    "# df['price_change'][df['price_diff'] < -thresh] = 0 # downward price movement\n",
    "# df['price_change'][df['price_diff'] > thresh] = 2 # upward prive movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>sin_day</th>\n",
       "      <th>cos_day</th>\n",
       "      <th>sin_hour</th>\n",
       "      <th>cos_hour</th>\n",
       "      <th>sin_minute</th>\n",
       "      <th>cos_minute</th>\n",
       "      <th>price_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-01 04:30:00</th>\n",
       "      <td>115.634512</td>\n",
       "      <td>115.792604</td>\n",
       "      <td>115.407254</td>\n",
       "      <td>115.407254</td>\n",
       "      <td>13550.0</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.665539e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-0.207496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 04:45:00</th>\n",
       "      <td>115.367731</td>\n",
       "      <td>115.367731</td>\n",
       "      <td>115.120712</td>\n",
       "      <td>115.308447</td>\n",
       "      <td>12857.0</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-0.098808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 05:00:00</th>\n",
       "      <td>115.308447</td>\n",
       "      <td>115.397374</td>\n",
       "      <td>115.298566</td>\n",
       "      <td>115.318327</td>\n",
       "      <td>10079.0</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.009881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 05:15:00</th>\n",
       "      <td>115.417135</td>\n",
       "      <td>115.604869</td>\n",
       "      <td>115.377612</td>\n",
       "      <td>115.604869</td>\n",
       "      <td>3534.0</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.832769e-16</td>\n",
       "      <td>0.286542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 05:30:00</th>\n",
       "      <td>115.604869</td>\n",
       "      <td>115.703677</td>\n",
       "      <td>115.555466</td>\n",
       "      <td>115.703677</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>5.665539e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.098808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           open        high         low       close   volume  \\\n",
       "time                                                                           \n",
       "2020-10-01 04:30:00  115.634512  115.792604  115.407254  115.407254  13550.0   \n",
       "2020-10-01 04:45:00  115.367731  115.367731  115.120712  115.308447  12857.0   \n",
       "2020-10-01 05:00:00  115.308447  115.397374  115.298566  115.318327  10079.0   \n",
       "2020-10-01 05:15:00  115.417135  115.604869  115.377612  115.604869   3534.0   \n",
       "2020-10-01 05:30:00  115.604869  115.703677  115.555466  115.703677   7688.0   \n",
       "\n",
       "                      sin_day   cos_day  sin_hour  cos_hour    sin_minute  \\\n",
       "time                                                                        \n",
       "2020-10-01 04:30:00  0.433884 -0.900969  0.866025  0.500000  5.665539e-16   \n",
       "2020-10-01 04:45:00  0.433884 -0.900969  0.866025  0.500000 -1.000000e+00   \n",
       "2020-10-01 05:00:00  0.433884 -0.900969  0.965926  0.258819  0.000000e+00   \n",
       "2020-10-01 05:15:00  0.433884 -0.900969  0.965926  0.258819  1.000000e+00   \n",
       "2020-10-01 05:30:00  0.433884 -0.900969  0.965926  0.258819  5.665539e-16   \n",
       "\n",
       "                       cos_minute  price_diff  \n",
       "time                                           \n",
       "2020-10-01 04:30:00 -1.000000e+00   -0.207496  \n",
       "2020-10-01 04:45:00 -1.836970e-16   -0.098808  \n",
       "2020-10-01 05:00:00  1.000000e+00    0.009881  \n",
       "2020-10-01 05:15:00  2.832769e-16    0.286542  \n",
       "2020-10-01 05:30:00 -1.000000e+00    0.098808  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Standardized train, valid, and test sets\n",
    "\n",
    "Split into train, valid, and test sets. And then standardize with training mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16112, 12)\n",
      "(9243, 12)\n",
      "(6267, 12)\n"
     ]
    }
   ],
   "source": [
    "train_df = df.loc['2020-10-01':'2021-10-01']\n",
    "valid_df = df.loc['2021-10-02':'2022-05-01']\n",
    "test_df = df.loc['2022-05-02':]\n",
    "\n",
    "\n",
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "valid_df = (valid_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std\n",
    "\n",
    "\n",
    "print(train_df.shape)\n",
    "print(valid_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data Generator for each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = WindowGenerator(\n",
    "                input_width=10, label_width=1, shift=1, \n",
    "                train_df=train_df, valid_df=valid_df, test_df=test_df,\n",
    "                label_columns=['price_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape (batch, time, features): (32, 10, 12)\n",
      "Targets shape (batch, time, features): (32, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in data_gen.train.take(1):\n",
    "    print(f'Inputs shape (batch, time, features): {inputs.shape}')\n",
    "    print(f'Targets shape (batch, time, features): {targets.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Start Training Models**\n",
    "\n",
    "First we will need a baseline model to compare our results to. The most simple baseline model will just predict the next value by using the previous value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(tf.keras.Model):\n",
    "    def __init__(self, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None:\n",
    "            return inputs\n",
    "        result = inputs[:, :, self.label_index]\n",
    "        return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_step_window = WindowGenerator(\n",
    "        input_width=1, label_width=1, shift=1,\n",
    "        train_df=train_df, valid_df=valid_df, test_df=test_df,\n",
    "        label_columns=['price_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 1s 4ms/step - loss: 4.0458 - mean_absolute_error: 1.2536\n"
     ]
    }
   ],
   "source": [
    "baseline = Baseline(label_index=single_step_window.column_indices['price_diff'])\n",
    "\n",
    "baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                 metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "val_performance = {}\n",
    "performance = {}\n",
    "val_performance['Baseline'] = baseline.evaluate(single_step_window.valid)\n",
    "performance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's train some more in depth models\n",
    "\n",
    "First we will define a helper function to streamline this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit(model, window, lr=1e-4, max_epochs=100, patience=2):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                      patience=patience,\n",
    "                                                      mode='min')\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit(window.train, epochs=max_epochs,\n",
    "                        validation_data=window.valid,\n",
    "                        callbacks=[early_stopping])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "504/504 [==============================] - 5s 7ms/step - loss: 1.0646 - mean_absolute_error: 0.6295 - val_loss: 2.0374 - val_mean_absolute_error: 0.8682\n",
      "Epoch 2/100\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 1.0122 - mean_absolute_error: 0.6069 - val_loss: 2.0355 - val_mean_absolute_error: 0.8676\n",
      "Epoch 3/100\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 1.0048 - mean_absolute_error: 0.6034 - val_loss: 2.0354 - val_mean_absolute_error: 0.8679\n",
      "Epoch 4/100\n",
      "504/504 [==============================] - 3s 7ms/step - loss: 1.0008 - mean_absolute_error: 0.6015 - val_loss: 2.0355 - val_mean_absolute_error: 0.8684\n",
      "Epoch 5/100\n",
      "504/504 [==============================] - 4s 8ms/step - loss: 0.9981 - mean_absolute_error: 0.6003 - val_loss: 2.0350 - val_mean_absolute_error: 0.8685\n",
      "Epoch 6/100\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.9959 - mean_absolute_error: 0.5994 - val_loss: 2.0351 - val_mean_absolute_error: 0.8688\n",
      "Epoch 7/100\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.9940 - mean_absolute_error: 0.5988 - val_loss: 2.0351 - val_mean_absolute_error: 0.8689\n",
      "289/289 [==============================] - 1s 4ms/step - loss: 2.0351 - mean_absolute_error: 0.8689\n"
     ]
    }
   ],
   "source": [
    "history = compile_and_fit(dense, single_step_window)\n",
    "\n",
    "val_performance['Dense'] = dense.evaluate(single_step_window.valid)\n",
    "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a dense NN model with a few time steps. We can use the Flatten() command to flatten out inputs as they are fed into the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_step_dense = tf.keras.Sequential([\n",
    "    # Shape: (time, features) => (time*features)\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1),\n",
    "    # Add back the time dimension.\n",
    "    # Shape: (outputs) => (1, outputs)\n",
    "    tf.keras.layers.Reshape([1, -1]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_window = WindowGenerator(\n",
    "        input_width=3, label_width=1, shift=1,\n",
    "        train_df=train_df, valid_df=valid_df, test_df=test_df,\n",
    "        label_columns=['price_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.9867 - mean_absolute_error: 0.5987 - val_loss: 2.0267 - val_mean_absolute_error: 0.8678\n",
      "Epoch 2/100\n",
      "504/504 [==============================] - 2s 4ms/step - loss: 0.9859 - mean_absolute_error: 0.5985 - val_loss: 2.0268 - val_mean_absolute_error: 0.8680\n",
      "Epoch 3/100\n",
      "504/504 [==============================] - 2s 4ms/step - loss: 0.9849 - mean_absolute_error: 0.5983 - val_loss: 2.0268 - val_mean_absolute_error: 0.8680\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 2.0268 - mean_absolute_error: 0.8680\n"
     ]
    }
   ],
   "source": [
    "history = compile_and_fit(multi_step_dense, conv_window)\n",
    "\n",
    "val_performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.valid)\n",
    "performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try an RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "504/504 [==============================] - 6s 9ms/step - loss: 1.0013 - mean_absolute_error: 0.5990 - val_loss: 2.0293 - val_mean_absolute_error: 0.8682\n",
      "Epoch 2/100\n",
      "504/504 [==============================] - 4s 8ms/step - loss: 1.0010 - mean_absolute_error: 0.5989 - val_loss: 2.0303 - val_mean_absolute_error: 0.8690\n",
      "Epoch 3/100\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 1.0007 - mean_absolute_error: 0.5987 - val_loss: 2.0315 - val_mean_absolute_error: 0.8698\n",
      "Epoch 4/100\n",
      "504/504 [==============================] - 4s 8ms/step - loss: 1.0005 - mean_absolute_error: 0.5986 - val_loss: 2.0327 - val_mean_absolute_error: 0.8706\n",
      "Epoch 5/100\n",
      "504/504 [==============================] - 4s 8ms/step - loss: 1.0003 - mean_absolute_error: 0.5985 - val_loss: 2.0339 - val_mean_absolute_error: 0.8714\n",
      "Epoch 6/100\n",
      "504/504 [==============================] - 4s 8ms/step - loss: 1.0001 - mean_absolute_error: 0.5985 - val_loss: 2.0350 - val_mean_absolute_error: 0.8722\n",
      "289/289 [==============================] - 1s 4ms/step - loss: 2.0350 - mean_absolute_error: 0.8722\n"
     ]
    }
   ],
   "source": [
    "history = compile_and_fit(lstm_model, data_gen, patience=5)\n",
    "\n",
    "val_performance['LSTM'] = lstm_model.evaluate(data_gen.valid)\n",
    "performance['LSTM'] = lstm_model.evaluate(data_gen.test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a Transformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "\n",
    "def build_model(\n",
    "            input_shape,\n",
    "            head_size,\n",
    "            num_heads,\n",
    "            ff_dim,\n",
    "            num_transformer_blocks,\n",
    "            mlp_units,\n",
    "            dropout=0,\n",
    "            mlp_dropout=0,\n",
    "        ):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = inputs.shape[1:]\n",
    "\n",
    "xformer_model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=256,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "504/504 [==============================] - 23s 33ms/step - loss: 1.0139 - mean_absolute_error: 0.6075 - val_loss: 2.0151 - val_mean_absolute_error: 0.8585\n",
      "Epoch 2/100\n",
      "504/504 [==============================] - 16s 33ms/step - loss: 1.0072 - mean_absolute_error: 0.6042 - val_loss: 2.0141 - val_mean_absolute_error: 0.8583\n",
      "Epoch 3/100\n",
      "504/504 [==============================] - 16s 32ms/step - loss: 1.0059 - mean_absolute_error: 0.6036 - val_loss: 2.0138 - val_mean_absolute_error: 0.8584\n",
      "Epoch 4/100\n",
      "504/504 [==============================] - 17s 33ms/step - loss: 1.0067 - mean_absolute_error: 0.6020 - val_loss: 2.0149 - val_mean_absolute_error: 0.8600\n",
      "Epoch 5/100\n",
      "504/504 [==============================] - 17s 35ms/step - loss: 1.0044 - mean_absolute_error: 0.6024 - val_loss: 2.0138 - val_mean_absolute_error: 0.8586\n",
      "Epoch 6/100\n",
      "504/504 [==============================] - 18s 35ms/step - loss: 1.0047 - mean_absolute_error: 0.6023 - val_loss: 2.0140 - val_mean_absolute_error: 0.8592\n",
      "Epoch 7/100\n",
      "504/504 [==============================] - 17s 34ms/step - loss: 1.0044 - mean_absolute_error: 0.6016 - val_loss: 2.0134 - val_mean_absolute_error: 0.8584\n",
      "Epoch 8/100\n",
      "504/504 [==============================] - 17s 33ms/step - loss: 1.0034 - mean_absolute_error: 0.6022 - val_loss: 2.0138 - val_mean_absolute_error: 0.8584\n",
      "Epoch 9/100\n",
      "504/504 [==============================] - 17s 34ms/step - loss: 1.0021 - mean_absolute_error: 0.6010 - val_loss: 2.0138 - val_mean_absolute_error: 0.8582\n",
      "Epoch 10/100\n",
      "504/504 [==============================] - 17s 33ms/step - loss: 1.0055 - mean_absolute_error: 0.6020 - val_loss: 2.0143 - val_mean_absolute_error: 0.8584\n",
      "Epoch 11/100\n",
      "504/504 [==============================] - 17s 34ms/step - loss: 1.0047 - mean_absolute_error: 0.6020 - val_loss: 2.0133 - val_mean_absolute_error: 0.8585\n",
      "Epoch 12/100\n",
      "504/504 [==============================] - 17s 33ms/step - loss: 1.0019 - mean_absolute_error: 0.6012 - val_loss: 2.0138 - val_mean_absolute_error: 0.8583\n",
      "Epoch 13/100\n",
      "504/504 [==============================] - 17s 33ms/step - loss: 1.0035 - mean_absolute_error: 0.6016 - val_loss: 2.0169 - val_mean_absolute_error: 0.8618\n",
      "Epoch 14/100\n",
      "504/504 [==============================] - 17s 33ms/step - loss: 1.0019 - mean_absolute_error: 0.6012 - val_loss: 2.0137 - val_mean_absolute_error: 0.8586\n",
      "Epoch 15/100\n",
      "504/504 [==============================] - 17s 33ms/step - loss: 1.0030 - mean_absolute_error: 0.6006 - val_loss: 2.0137 - val_mean_absolute_error: 0.8586\n",
      "Epoch 16/100\n",
      "504/504 [==============================] - 17s 33ms/step - loss: 1.0007 - mean_absolute_error: 0.5998 - val_loss: 2.0155 - val_mean_absolute_error: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b291db4520>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compile_and_fit(xformer_model, data_gen, lr=1e-4, max_epochs=100, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 3s 11ms/step - loss: 2.0155 - mean_absolute_error: 0.8600\n"
     ]
    }
   ],
   "source": [
    "val_performance['xformer'] = xformer_model.evaluate(data_gen.valid)\n",
    "performance['xfomrer'] = xformer_model.evaluate(data_gen.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Baseline': [4.045819282531738, 1.2536100149154663],\n",
       " 'Dense': [2.035062313079834, 0.8688646554946899],\n",
       " 'Multi step dense': [2.0267698764801025, 0.867950439453125],\n",
       " 'LSTM': [2.034999132156372, 0.8721564412117004],\n",
       " 'xformer': [2.0155041217803955, 0.8600403666496277]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 1, 1), dtype=float32, numpy=\n",
       "array([[[ 0.09696072]],\n",
       "\n",
       "       [[ 0.33631903]],\n",
       "\n",
       "       [[-0.48091865]],\n",
       "\n",
       "       [[-0.24839914]],\n",
       "\n",
       "       [[ 0.5414833 ]],\n",
       "\n",
       "       [[-0.3766268 ]],\n",
       "\n",
       "       [[ 0.7757125 ]],\n",
       "\n",
       "       [[ 1.3279463 ]],\n",
       "\n",
       "       [[-1.202413  ]],\n",
       "\n",
       "       [[-0.79208446]],\n",
       "\n",
       "       [[ 0.7808416 ]],\n",
       "\n",
       "       [[-2.5530777 ]],\n",
       "\n",
       "       [[-1.8350028 ]],\n",
       "\n",
       "       [[ 0.81503564]],\n",
       "\n",
       "       [[-0.03947352]],\n",
       "\n",
       "       [[ 0.54114133]],\n",
       "\n",
       "       [[-0.1601785 ]],\n",
       "\n",
       "       [[-1.2793496 ]],\n",
       "\n",
       "       [[ 0.8755591 ]],\n",
       "\n",
       "       [[ 0.07234101]],\n",
       "\n",
       "       [[-1.2290844 ]],\n",
       "\n",
       "       [[-0.6724053 ]],\n",
       "\n",
       "       [[ 0.44163668]],\n",
       "\n",
       "       [[-0.24805719]],\n",
       "\n",
       "       [[ 0.5076312 ]],\n",
       "\n",
       "       [[ 0.37051308]],\n",
       "\n",
       "       [[-0.20565657]],\n",
       "\n",
       "       [[ 0.9589926 ]],\n",
       "\n",
       "       [[-0.8043943 ]],\n",
       "\n",
       "       [[-0.7917425 ]],\n",
       "\n",
       "       [[ 0.74391204]],\n",
       "\n",
       "       [[ 1.0738846 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 1), dtype=float32, numpy=\n",
       "array([[ 0.07047774],\n",
       "       [ 0.08038411],\n",
       "       [ 0.05739209],\n",
       "       [ 0.05441375],\n",
       "       [ 0.06962143],\n",
       "       [ 0.06844871],\n",
       "       [ 0.07363428],\n",
       "       [ 0.03191207],\n",
       "       [ 0.05784791],\n",
       "       [ 0.11115447],\n",
       "       [ 0.05245746],\n",
       "       [ 0.0112911 ],\n",
       "       [ 0.11171508],\n",
       "       [ 0.10598822],\n",
       "       [ 0.01331589],\n",
       "       [ 0.03273129],\n",
       "       [ 0.05926988],\n",
       "       [ 0.07002015],\n",
       "       [ 0.06132753],\n",
       "       [-0.00444111],\n",
       "       [ 0.00827672],\n",
       "       [ 0.06400785],\n",
       "       [ 0.04987158],\n",
       "       [-0.03143305],\n",
       "       [ 0.00879576],\n",
       "       [ 0.07991422],\n",
       "       [ 0.04328666],\n",
       "       [-0.0254989 ],\n",
       "       [-0.01554505],\n",
       "       [ 0.06986066],\n",
       "       [ 0.04208784],\n",
       "       [-0.04300736]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xformer_model(inputs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to determine how well the model predicts the upcoming price movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = tf.squeeze(xformer_model(inputs))\n",
    "y = tf.squeeze(targets)\n",
    "\n",
    "true_moves = np.ones_like(y.numpy())\n",
    "true_moves[y > 0.1] = 2\n",
    "true_moves[y < -0.1] = 0\n",
    "\n",
    "pred_moves = np.ones_like(yhat.numpy())\n",
    "pred_moves[yhat > 0.1] = 2\n",
    "pred_moves[yhat < -0.1] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_moves = tf.convert_to_tensor(true_moves)\n",
    "pred_moves = tf.convert_to_tensor(pred_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 2., 2., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.boolean_mask(tmp, tf.greater(y, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_movement_loss(y, yhat, thresh=0.1):\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b2da39daaaff30a84159e8452ba91acfc0bbd521fb66c6aa9941f847b87bd81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
