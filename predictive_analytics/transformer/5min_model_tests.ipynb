{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5min stock data**\n",
    "\n",
    "In this notebook we will explore a basic pipeline for 5min interval stock data. We will be working with a portfolio of highly correlated stocks: AAPL, GOOG, QCOM, and TSLA. We will train our models using the Balanced Focal Loss function and compare it to our previous performan using Categorical Cross Entropy Loss. These stocks were highly correlated around Aug - Oct 2022. The stock dataset contains timestamps, prices and trading volume, but does not contin any target variables.\n",
    "- Timestamps &#8594; Interval\n",
    "- Open/Close/High/Low Prices &#8594; Ratio\n",
    "- Trading Volume &#8594; Ratio\n",
    "\n",
    "To use the timestamps we will sinusoidally encode them. We will also add engineered features such as the price difference.\n",
    "\n",
    " We will create the target variable by taking the midpoint of Open/Close prices for M future days and then averaging these values. This target variable is Oridnal and has 3 possible classes: \n",
    "- 0 - downward price movement\n",
    "- 1 - no change\n",
    "- 2 - upward price movement\n",
    "\n",
    "The price movements are derived by a threshold that is defined using the IQR method to detect outliers. Currently we use a limit of 1, and every Q1 outlier is classified as \"0 - downward price movement\", every Q3 outlier is classified as \"2 - upward price movement\", and all inliers are classified as: \"1 - no change\".\n",
    "\n",
    "#### NOTE:\n",
    "This dataset has discontinuities after each trading day (i.e. from final afterhours trade until the first afterhours trade the next day). It is possible that other afterhours activities could have occured to impact the prices during this time period. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "The main model we will be testing in this notebook is a Transformer Encoder. Typically a Transformer has an Encoder and Decoder portion, where the Encoder learns information about which parts of the input sequence are relevant to eachother. The Decoder does the opposite, it takes the continuouss representation learned by the Encoder and learns to generate an ordered output sequence. For the Time Series Classifiecation problem it is unecessary to include the Decoder, we can simply use the Encoder to learn relative correlations of the inputs and add a Vanilla Feed Forward Neural Network to the end of the Encoder Blocks to obtain the desired classification. [Source](https://userweb.cs.txstate.edu/~amk181/AIME_LSTM_Attention_vs_Transformer.pdf).\n",
    "\n",
    "The Transformer Encoder also relies on positional encoding in order to implement this, we will first project the input vectors into high dimensional space as done [here](https://arxiv.org/pdf/2010.02803.pdf), and then add the positional Encoding as done in the [original paper](https://arxiv.org/pdf/1706.03762.pdf).\n",
    "\n",
    "\n",
    "In order to compare how effective the Transformer is in modeling seuqential data, we will compare its results to:\n",
    "- Baseline Model (uses previous predictions)\n",
    "- Linear Model\n",
    "- Neural Network\n",
    "- LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Imports\n",
    "\n",
    "Get base dir for imports, this allows us to look in the main algotrading folder to import local modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath(os.path.join(os.path.abspath('..'), '..'))\n",
    "sys.path.append(BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import *\n",
    "from data_pipeline import *\n",
    "from window_generator import WindowGenerator\n",
    "from models.basic_transformer import TransformerModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure that GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data\n",
    "Place all stocks in a Dictionary of DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\itber\\Documents\\learning\\school\\ESE527\\project\\algotrading\\data_pipeline.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['price_change'][df['price_trend'] < lower] = 0 # downward price movement\n",
      "c:\\Users\\itber\\Documents\\learning\\school\\ESE527\\project\\algotrading\\data_pipeline.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['price_change'][df['price_trend'] > upper] = 2 # upward prive movement\n",
      "c:\\Users\\itber\\Documents\\learning\\school\\ESE527\\project\\algotrading\\data_pipeline.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['price_change'][df['price_trend'] < lower] = 0 # downward price movement\n",
      "c:\\Users\\itber\\Documents\\learning\\school\\ESE527\\project\\algotrading\\data_pipeline.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['price_change'][df['price_trend'] > upper] = 2 # upward prive movement\n",
      "c:\\Users\\itber\\Documents\\learning\\school\\ESE527\\project\\algotrading\\data_pipeline.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['price_change'][df['price_trend'] < lower] = 0 # downward price movement\n",
      "c:\\Users\\itber\\Documents\\learning\\school\\ESE527\\project\\algotrading\\data_pipeline.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['price_change'][df['price_trend'] > upper] = 2 # upward prive movement\n",
      "c:\\Users\\itber\\Documents\\learning\\school\\ESE527\\project\\algotrading\\data_pipeline.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['price_change'][df['price_trend'] < lower] = 0 # downward price movement\n",
      "c:\\Users\\itber\\Documents\\learning\\school\\ESE527\\project\\algotrading\\data_pipeline.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['price_change'][df['price_trend'] > upper] = 2 # upward prive movement\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import re\n",
    "\n",
    "# get all data .csvs\n",
    "data_paths = glob(os.path.join(BASE_DIR, r'data\\raw\\5min\\*.csv'))\n",
    "\n",
    "# get stock DataFrames dict\n",
    "stock_dfs = get_stocks(data_paths, tgt_window=4, iqr_lim=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the of number of each class for each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "for i, name in enumerate(stock_dfs.keys()):\n",
    "    # get plotting axes\n",
    "    ax = plt.subplot(2, 2, i + 1)\n",
    "\n",
    "    # get stock DataFrame\n",
    "    df = stock_dfs[name]\n",
    "\n",
    "    # compute class counts\n",
    "    down = np.sum(df.price_change == 0)\n",
    "    none = np.sum(df.price_change == 1)\n",
    "    up = np.sum(df.price_change == 2)\n",
    "\n",
    "    ax.barh([2.25], [0]) # expand to fit the legend\n",
    "    ax.barh([0], [down], height=0.4, edgecolor='k', label='num_downward')\n",
    "    ax.barh([1], [none], height=0.4, edgecolor='k', label='num_no_change')\n",
    "    ax.barh([2], [up], height=0.4, edgecolor='k', label='num_upward')\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel('Number of Samples')\n",
    "    ax.set_ylabel('Price Movement Class')\n",
    "    ax.legend();\n",
    "\n",
    "# set main title\n",
    "fig.suptitle('Number of training samples in each class', size=24)\n",
    "\n",
    "# add a bit of space\n",
    "fig.subplots_adjust(hspace=0.35);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Day of Week to features and remove later\n",
    "We will use the dayofweek to remove windows containing non-consecutive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in stock_dfs.keys():\n",
    "    df = stock_dfs[name]\n",
    "    df['dayofweek'] =  df.index.dayofweek\n",
    "\n",
    "    stock_dfs[name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93274, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_dfs['AAPL'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69493, 16)\n",
      "(13015, 16)\n",
      "(10766, 16)\n"
     ]
    }
   ],
   "source": [
    "print(stock_dfs['AAPL'].loc[:'2022-05-01'].shape)\n",
    "print(stock_dfs['AAPL'].loc['2022-05-02':'2022-08-09'].shape)\n",
    "print(stock_dfs['AAPL'].loc['2022-08-10':].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get train, valid, test splits for each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dfs = get_split_dfs(stock_dfs, train_loc='2022-05-01', \n",
    "                          valid_loc_1='2022-05-02', valid_loc_2='2022-08-09', \n",
    "                          test_loc='2022-08-10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data Generators\n",
    "- One for baseline model\n",
    "- One for simple non-sequential models (this will use window normalization)\n",
    "- One for sequential models (This will use window normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to make a Data Generator that that can account for the time spans that we are interested in. We might be able to use specific timestamps to define the windows, i.e. 09:30-13:30\n",
    "\n",
    "We should strive for a general method of doing this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data Generators\n",
    "We will add data generators for each stock to dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_gens = {}\n",
    "single_gens = {}\n",
    "window_gens = {}\n",
    "    \n",
    "for name in stock_dfs.keys():\n",
    "    base_gen = WindowGenerator(\n",
    "                input_width=1, label_width=1, shift=0,\n",
    "                sample_weights=False,\n",
    "                dfs=split_dfs[name],\n",
    "                batch_size=32, \n",
    "                label_columns=['price_change'])\n",
    "\n",
    "    single_gen = WindowGenerator(\n",
    "                input_width=1, label_width=1, shift=0, \n",
    "                sample_weights=False,\n",
    "                window_norm=False,\n",
    "                dfs=split_dfs[name],\n",
    "                remove_columns=['price_change', 'price_trend', 'dayofweek'],\n",
    "                batch_size=32, \n",
    "                remove_nonsequential=True,\n",
    "                label_columns=['price_change'])\n",
    "\n",
    "    window_normed_gen = WindowGenerator(\n",
    "                input_width=32, label_width=1, shift=0, \n",
    "                sample_weights=False,\n",
    "                window_norm=True,\n",
    "                dfs=split_dfs[name],\n",
    "                remove_columns=['price_change', 'price_trend', 'dayofweek'],\n",
    "                batch_size=32, \n",
    "                remove_nonsequential=True, # keep only simultaneous batch windows\n",
    "                label_columns=['price_change'])\n",
    "\n",
    "    # add to data generators\n",
    "    base_gens.update({name : base_gen})\n",
    "    single_gens.update({name : single_gen})\n",
    "    window_gens.update({name : window_normed_gen})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape (batch, time, features): (32, 32, 13)\n",
      "Labels shape (batch, time, features): (32, 1, 1)\n",
      "Inputs shape (batch, time, features): (32, 32, 13)\n",
      "Labels shape (batch, time, features): (32, 1, 1)\n",
      "Inputs shape (batch, time, features): (32, 32, 13)\n",
      "Labels shape (batch, time, features): (32, 1, 1)\n",
      "Inputs shape (batch, time, features): (32, 32, 13)\n",
      "Labels shape (batch, time, features): (32, 1, 1)\n",
      "Inputs shape (batch, time, features): (32, 32, 13)\n",
      "Labels shape (batch, time, features): (32, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in window_gens['AAPL'].train.take(5):\n",
    "    print(f'Inputs shape (batch, time, features): {inputs.shape}')\n",
    "    print(f'Labels shape (batch, time, features): {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc_metric(y_true, y_pred, num_classes=3, threshold=0.5):\n",
    "    ''' Custom Mathew Correlation Coefficient for multiclass \n",
    "        For more details see: \n",
    "            \"https://en.wikipedia.org/wiki/Phi_coefficient\"\n",
    "        Inputs: \n",
    "            y_true (tensor)\n",
    "            y_pred (tensor)\n",
    "            num_classes - number of classes\n",
    "        Outputs:\n",
    "            mcc - Mathews Correlation Coefficient\n",
    "        '''\n",
    "    # obtain predictions here, we can add in a threshold if we would like to\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "\n",
    "    # cast to int64\n",
    "    y_true = tf.squeeze(tf.cast(y_true, tf.int64), axis=-1)\n",
    "    y_pred = tf.cast(y_pred, tf.int64)\n",
    "\n",
    "    # total number of samples\n",
    "    s = tf.size(y_true, out_type=tf.int64)\n",
    "\n",
    "    # total number of correctly predicted labels\n",
    "    c = s - tf.math.count_nonzero(y_true - y_pred)\n",
    "    \n",
    "    # number of times each class truely occured\n",
    "    t = []\n",
    "\n",
    "    # number of times each class was predicted\n",
    "    p = []\n",
    "\n",
    "    for k in range(num_classes):\n",
    "        k = tf.cast(k, tf.int64)\n",
    "        \n",
    "        # number of times that the class truely occured\n",
    "        t.append(tf.reduce_sum(tf.cast(tf.equal(k, y_true), tf.int32)))\n",
    "\n",
    "        # number of times that the class was predicted\n",
    "        p.append(tf.reduce_sum(tf.cast(tf.equal(k, y_pred), tf.int32)))\n",
    "\n",
    "\n",
    "    t = tf.expand_dims(tf.stack(t), 0)\n",
    "    p = tf.expand_dims(tf.stack(p), 0)\n",
    "\n",
    "    s = tf.cast(s, tf.int32)\n",
    "    c = tf.cast(c, tf.int32)\n",
    "    \n",
    "    num = tf.cast(c*s - tf.matmul(t, tf.transpose(p)), tf.float32)\n",
    "    dem = tf.math.sqrt(tf.cast(s**2 - tf.matmul(p, tf.transpose(p)), tf.float32)) \\\n",
    "          * tf.math.sqrt(tf.cast(s**2 - tf.matmul(t, tf.transpose(t)), tf.float32))\n",
    "\n",
    "\n",
    "    mcc = tf.divide(num, dem + 1e-6)\n",
    "\n",
    "    return mcc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use Mathews Correlation Coefficient with predicted class probabilities, we will override thhe update_state function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(tf.keras.Model):\n",
    "    def __init__(self, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None:\n",
    "            return inputs\n",
    "        result = inputs[:, :, self.label_index]\n",
    "        return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_performance = {}\n",
    "val_performance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2172/2172 [==============================] - 8s 3ms/step - loss: nan - mcc_metric: 0.0000e+00 - accuracy: 0.1725\n",
      "407/407 [==============================] - 1s 3ms/step - loss: nan - mcc_metric: 0.0000e+00 - accuracy: 0.2232\n",
      "1068/1068 [==============================] - 4s 3ms/step - loss: nan - mcc_metric: 0.0000e+00 - accuracy: 0.1737\n",
      "246/246 [==============================] - 1s 3ms/step - loss: nan - mcc_metric: 0.0000e+00 - accuracy: 0.2153\n",
      "1438/1438 [==============================] - 5s 3ms/step - loss: nan - mcc_metric: 0.0000e+00 - accuracy: 0.1697\n",
      "265/265 [==============================] - 1s 3ms/step - loss: nan - mcc_metric: 0.0000e+00 - accuracy: 0.2187\n",
      "2094/2094 [==============================] - 7s 3ms/step - loss: nan - mcc_metric: 0.0000e+00 - accuracy: 0.1843\n",
      "400/400 [==============================] - 1s 3ms/step - loss: nan - mcc_metric: 0.0000e+00 - accuracy: 0.2061\n"
     ]
    }
   ],
   "source": [
    "for name in base_gens.keys():\n",
    "    baseline = Baseline(label_index=base_gen.column_indices['price_change'])\n",
    "\n",
    "    baseline.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                    metrics=[mcc_metric, 'accuracy'],\n",
    "                    # weighted_metrics=['accuracy'],\n",
    "                    )\n",
    "\n",
    "    train_performance[f'Baseline_{name}'] = baseline.evaluate(base_gens[name].train)\n",
    "    val_performance[f'Baseline_{name}'] = baseline.evaluate(base_gens[name].valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a function to streamline the rest of the training process. First we will compute normalized class weights to help with the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(dfs, name):\n",
    "    class_counts = np.bincount(dfs[name][0].price_change)\n",
    "    total = class_counts.sum()\n",
    "    n_classes = len(class_counts)\n",
    "\n",
    "    weights = []\n",
    "    for idx, count in enumerate(class_counts):\n",
    "        # compute balanced weights\n",
    "        weights.append(total / (n_classes*count))\n",
    "\n",
    "        # get inverse frequency class weighting\n",
    "        # weights.append(1/np.power(count, 1))\n",
    "\n",
    "\n",
    "    weights = np.array(weights) \n",
    "    # weights = weights / weights.sum()\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focal_loss import SparseCategoricalFocalLoss\n",
    "\n",
    "def compile_and_fit(model, window, lr=1e-4, max_epochs=100, lr_scheduler=None, patience=5, weights=None):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                      patience=patience,\n",
    "                                                      mode='min')\n",
    "\n",
    "    \n",
    "    model.compile(\n",
    "        # loss=SparseCategoricalFocalLoss(gamma=2, class_weight=weights),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy(), mcc_metric],\n",
    "        # weighted_metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "        )\n",
    "\n",
    "    if lr_scheduler:\n",
    "        lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "        history = model.fit(window.train, epochs=max_epochs,\n",
    "                            validation_data=window.valid,\n",
    "                            callbacks=[lr_callback, early_stopping])\n",
    "    else:\n",
    "        history = model.fit(window.train, epochs=max_epochs,\n",
    "                            validation_data=window.valid,\n",
    "                            callbacks=[early_stopping])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Linear model\n",
    "Entire dataset is standardized here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2172/2172 [==============================] - 14s 6ms/step - loss: 1.2062 - sparse_categorical_accuracy: 0.6224 - mcc_metric: 0.0947 - val_loss: 1.5503 - val_sparse_categorical_accuracy: 0.4379 - val_mcc_metric: 0.0879\n",
      "Epoch 2/30\n",
      "2172/2172 [==============================] - 12s 6ms/step - loss: 1.1552 - sparse_categorical_accuracy: 0.6308 - mcc_metric: 0.0961 - val_loss: 1.3985 - val_sparse_categorical_accuracy: 0.4373 - val_mcc_metric: 0.0880\n",
      "Epoch 3/30\n",
      "2172/2172 [==============================] - 13s 6ms/step - loss: 1.1552 - sparse_categorical_accuracy: 0.6309 - mcc_metric: 0.0990 - val_loss: 1.7599 - val_sparse_categorical_accuracy: 0.3830 - val_mcc_metric: 0.0723\n",
      "Epoch 4/30\n",
      "2172/2172 [==============================] - 12s 6ms/step - loss: 1.1582 - sparse_categorical_accuracy: 0.6313 - mcc_metric: 0.0974 - val_loss: 1.8545 - val_sparse_categorical_accuracy: 0.3840 - val_mcc_metric: 0.0772\n",
      "Epoch 5/30\n",
      "2172/2172 [==============================] - 13s 6ms/step - loss: 1.1397 - sparse_categorical_accuracy: 0.6319 - mcc_metric: 0.1006 - val_loss: 2.0052 - val_sparse_categorical_accuracy: 0.3912 - val_mcc_metric: 0.0829\n",
      "Epoch 6/30\n",
      "2172/2172 [==============================] - 14s 6ms/step - loss: 1.1792 - sparse_categorical_accuracy: 0.6270 - mcc_metric: 0.0973 - val_loss: 1.5448 - val_sparse_categorical_accuracy: 0.4391 - val_mcc_metric: 0.0985\n",
      "Epoch 7/30\n",
      "2172/2172 [==============================] - 13s 6ms/step - loss: 1.1553 - sparse_categorical_accuracy: 0.6310 - mcc_metric: 0.0954 - val_loss: 1.3874 - val_sparse_categorical_accuracy: 0.4450 - val_mcc_metric: 0.0761\n",
      "Epoch 8/30\n",
      "2172/2172 [==============================] - 12s 6ms/step - loss: 1.1370 - sparse_categorical_accuracy: 0.6349 - mcc_metric: 0.0986 - val_loss: 1.4065 - val_sparse_categorical_accuracy: 0.4306 - val_mcc_metric: 0.0759\n",
      "Epoch 9/30\n",
      "2172/2172 [==============================] - 12s 6ms/step - loss: 1.1436 - sparse_categorical_accuracy: 0.6323 - mcc_metric: 0.0996 - val_loss: 1.6283 - val_sparse_categorical_accuracy: 0.4091 - val_mcc_metric: 0.0808\n",
      "Epoch 10/30\n",
      "2172/2172 [==============================] - 12s 6ms/step - loss: 1.1669 - sparse_categorical_accuracy: 0.6318 - mcc_metric: 0.0959 - val_loss: 1.6274 - val_sparse_categorical_accuracy: 0.4347 - val_mcc_metric: 0.0883\n",
      "Epoch 11/30\n",
      "2172/2172 [==============================] - 12s 6ms/step - loss: 1.1745 - sparse_categorical_accuracy: 0.6312 - mcc_metric: 0.0956 - val_loss: 1.5056 - val_sparse_categorical_accuracy: 0.4346 - val_mcc_metric: 0.0950\n",
      "Epoch 12/30\n",
      "2172/2172 [==============================] - 12s 6ms/step - loss: 1.1532 - sparse_categorical_accuracy: 0.6319 - mcc_metric: 0.0963 - val_loss: 1.5238 - val_sparse_categorical_accuracy: 0.4296 - val_mcc_metric: 0.0891\n",
      "Epoch 1/30\n",
      "1068/1068 [==============================] - 7s 6ms/step - loss: 0.9937 - sparse_categorical_accuracy: 0.6204 - mcc_metric: 0.0572 - val_loss: 1.3678 - val_sparse_categorical_accuracy: 0.3158 - val_mcc_metric: 0.0175\n",
      "Epoch 2/30\n",
      "1068/1068 [==============================] - 6s 6ms/step - loss: 1.0064 - sparse_categorical_accuracy: 0.6190 - mcc_metric: 0.0579 - val_loss: 1.3512 - val_sparse_categorical_accuracy: 0.3166 - val_mcc_metric: 0.0123\n",
      "Epoch 3/30\n",
      "1068/1068 [==============================] - 6s 6ms/step - loss: 1.0135 - sparse_categorical_accuracy: 0.6182 - mcc_metric: 0.0596 - val_loss: 1.3447 - val_sparse_categorical_accuracy: 0.3162 - val_mcc_metric: 0.0122\n",
      "Epoch 4/30\n",
      "1068/1068 [==============================] - 6s 6ms/step - loss: 1.0114 - sparse_categorical_accuracy: 0.6184 - mcc_metric: 0.0593 - val_loss: 1.3430 - val_sparse_categorical_accuracy: 0.3167 - val_mcc_metric: 0.0133\n",
      "Epoch 5/30\n",
      "1068/1068 [==============================] - 6s 6ms/step - loss: 1.0110 - sparse_categorical_accuracy: 0.6185 - mcc_metric: 0.0592 - val_loss: 1.3427 - val_sparse_categorical_accuracy: 0.3167 - val_mcc_metric: 0.0133\n",
      "Epoch 6/30\n",
      "1068/1068 [==============================] - 6s 6ms/step - loss: 1.0110 - sparse_categorical_accuracy: 0.6185 - mcc_metric: 0.0591 - val_loss: 1.3427 - val_sparse_categorical_accuracy: 0.3170 - val_mcc_metric: 0.0137\n",
      "Epoch 7/30\n",
      "1068/1068 [==============================] - 6s 6ms/step - loss: 1.0109 - sparse_categorical_accuracy: 0.6185 - mcc_metric: 0.0590 - val_loss: 1.3425 - val_sparse_categorical_accuracy: 0.3172 - val_mcc_metric: 0.0141\n",
      "Epoch 8/30\n",
      "1068/1068 [==============================] - 6s 6ms/step - loss: 1.0107 - sparse_categorical_accuracy: 0.6185 - mcc_metric: 0.0591 - val_loss: 1.3428 - val_sparse_categorical_accuracy: 0.3174 - val_mcc_metric: 0.0140\n",
      "Epoch 9/30\n",
      "1068/1068 [==============================] - 6s 6ms/step - loss: 1.0106 - sparse_categorical_accuracy: 0.6184 - mcc_metric: 0.0589 - val_loss: 1.3429 - val_sparse_categorical_accuracy: 0.3181 - val_mcc_metric: 0.0146\n",
      "Epoch 10/30\n",
      "1068/1068 [==============================] - 6s 6ms/step - loss: 1.0105 - sparse_categorical_accuracy: 0.6186 - mcc_metric: 0.0591 - val_loss: 1.3431 - val_sparse_categorical_accuracy: 0.3179 - val_mcc_metric: 0.0142\n",
      "Epoch 11/30\n",
      "1068/1068 [==============================] - 6s 6ms/step - loss: 1.0103 - sparse_categorical_accuracy: 0.6186 - mcc_metric: 0.0593 - val_loss: 1.3432 - val_sparse_categorical_accuracy: 0.3184 - val_mcc_metric: 0.0149\n",
      "Epoch 12/30\n",
      "1068/1068 [==============================] - 6s 6ms/step - loss: 1.0101 - sparse_categorical_accuracy: 0.6186 - mcc_metric: 0.0591 - val_loss: 1.3434 - val_sparse_categorical_accuracy: 0.3189 - val_mcc_metric: 0.0158\n",
      "Epoch 1/30\n",
      "1438/1438 [==============================] - 8s 6ms/step - loss: 1.1890 - sparse_categorical_accuracy: 0.6156 - mcc_metric: 0.0582 - val_loss: 1.1131 - val_sparse_categorical_accuracy: 0.4388 - val_mcc_metric: 0.1009\n",
      "Epoch 2/30\n",
      "1438/1438 [==============================] - 8s 5ms/step - loss: 1.1510 - sparse_categorical_accuracy: 0.6226 - mcc_metric: 0.0577 - val_loss: 1.0944 - val_sparse_categorical_accuracy: 0.4732 - val_mcc_metric: 0.1104\n",
      "Epoch 3/30\n",
      "1438/1438 [==============================] - 8s 5ms/step - loss: 1.1332 - sparse_categorical_accuracy: 0.6224 - mcc_metric: 0.0556 - val_loss: 1.0899 - val_sparse_categorical_accuracy: 0.4678 - val_mcc_metric: 0.1049\n",
      "Epoch 4/30\n",
      "1438/1438 [==============================] - 10s 7ms/step - loss: 1.1296 - sparse_categorical_accuracy: 0.6222 - mcc_metric: 0.0556 - val_loss: 1.0879 - val_sparse_categorical_accuracy: 0.4672 - val_mcc_metric: 0.1052\n",
      "Epoch 5/30\n",
      "1438/1438 [==============================] - 8s 6ms/step - loss: 1.1275 - sparse_categorical_accuracy: 0.6218 - mcc_metric: 0.0542 - val_loss: 1.0866 - val_sparse_categorical_accuracy: 0.4669 - val_mcc_metric: 0.1059\n",
      "Epoch 6/30\n",
      "1438/1438 [==============================] - 8s 6ms/step - loss: 1.1263 - sparse_categorical_accuracy: 0.6220 - mcc_metric: 0.0551 - val_loss: 1.0853 - val_sparse_categorical_accuracy: 0.4673 - val_mcc_metric: 0.1069\n",
      "Epoch 7/30\n",
      "1438/1438 [==============================] - 8s 5ms/step - loss: 1.1261 - sparse_categorical_accuracy: 0.6221 - mcc_metric: 0.0555 - val_loss: 1.0832 - val_sparse_categorical_accuracy: 0.4685 - val_mcc_metric: 0.1069\n",
      "Epoch 8/30\n",
      "1438/1438 [==============================] - 8s 5ms/step - loss: 1.1245 - sparse_categorical_accuracy: 0.6220 - mcc_metric: 0.0555 - val_loss: 1.0818 - val_sparse_categorical_accuracy: 0.4699 - val_mcc_metric: 0.1086\n",
      "Epoch 9/30\n",
      "1438/1438 [==============================] - 8s 5ms/step - loss: 1.1238 - sparse_categorical_accuracy: 0.6220 - mcc_metric: 0.0553 - val_loss: 1.0798 - val_sparse_categorical_accuracy: 0.4710 - val_mcc_metric: 0.1076\n",
      "Epoch 10/30\n",
      "1438/1438 [==============================] - 8s 5ms/step - loss: 1.1229 - sparse_categorical_accuracy: 0.6222 - mcc_metric: 0.0558 - val_loss: 1.0783 - val_sparse_categorical_accuracy: 0.4719 - val_mcc_metric: 0.1078\n",
      "Epoch 11/30\n",
      "1438/1438 [==============================] - 7s 5ms/step - loss: 1.1226 - sparse_categorical_accuracy: 0.6224 - mcc_metric: 0.0563 - val_loss: 1.0764 - val_sparse_categorical_accuracy: 0.4735 - val_mcc_metric: 0.1086\n",
      "Epoch 12/30\n",
      "1438/1438 [==============================] - 8s 5ms/step - loss: 1.1225 - sparse_categorical_accuracy: 0.6228 - mcc_metric: 0.0570 - val_loss: 1.0748 - val_sparse_categorical_accuracy: 0.4753 - val_mcc_metric: 0.1086\n",
      "Epoch 13/30\n",
      "1438/1438 [==============================] - 7s 5ms/step - loss: 1.1224 - sparse_categorical_accuracy: 0.6229 - mcc_metric: 0.0573 - val_loss: 1.0735 - val_sparse_categorical_accuracy: 0.4770 - val_mcc_metric: 0.1086\n",
      "Epoch 14/30\n",
      "1438/1438 [==============================] - 8s 5ms/step - loss: 1.1221 - sparse_categorical_accuracy: 0.6228 - mcc_metric: 0.0569 - val_loss: 1.0723 - val_sparse_categorical_accuracy: 0.4784 - val_mcc_metric: 0.1091\n",
      "Epoch 15/30\n",
      "1438/1438 [==============================] - 8s 5ms/step - loss: 1.1210 - sparse_categorical_accuracy: 0.6229 - mcc_metric: 0.0575 - val_loss: 1.0714 - val_sparse_categorical_accuracy: 0.4797 - val_mcc_metric: 0.1096\n",
      "Epoch 16/30\n",
      "1438/1438 [==============================] - 7s 5ms/step - loss: 1.1236 - sparse_categorical_accuracy: 0.6234 - mcc_metric: 0.0588 - val_loss: 1.0698 - val_sparse_categorical_accuracy: 0.4818 - val_mcc_metric: 0.1105\n",
      "Epoch 17/30\n",
      "1438/1438 [==============================] - 7s 5ms/step - loss: 1.1193 - sparse_categorical_accuracy: 0.6234 - mcc_metric: 0.0581 - val_loss: 1.0689 - val_sparse_categorical_accuracy: 0.4835 - val_mcc_metric: 0.1123\n",
      "Epoch 18/30\n",
      "1438/1438 [==============================] - 7s 5ms/step - loss: 1.1241 - sparse_categorical_accuracy: 0.6241 - mcc_metric: 0.0596 - val_loss: 1.0674 - val_sparse_categorical_accuracy: 0.4841 - val_mcc_metric: 0.1115\n",
      "Epoch 19/30\n",
      "1438/1438 [==============================] - 7s 5ms/step - loss: 1.1191 - sparse_categorical_accuracy: 0.6241 - mcc_metric: 0.0598 - val_loss: 1.0669 - val_sparse_categorical_accuracy: 0.4861 - val_mcc_metric: 0.1129\n",
      "Epoch 20/30\n",
      "1438/1438 [==============================] - 8s 5ms/step - loss: 1.1213 - sparse_categorical_accuracy: 0.6247 - mcc_metric: 0.0607 - val_loss: 1.0650 - val_sparse_categorical_accuracy: 0.4871 - val_mcc_metric: 0.1137\n",
      "Epoch 21/30\n",
      "1438/1438 [==============================] - 8s 5ms/step - loss: 1.1216 - sparse_categorical_accuracy: 0.6248 - mcc_metric: 0.0612 - val_loss: 1.0640 - val_sparse_categorical_accuracy: 0.4873 - val_mcc_metric: 0.1121\n",
      "Epoch 22/30\n",
      "1438/1438 [==============================] - 7s 5ms/step - loss: 1.1197 - sparse_categorical_accuracy: 0.6244 - mcc_metric: 0.0605 - val_loss: 1.0625 - val_sparse_categorical_accuracy: 0.4884 - val_mcc_metric: 0.1123\n",
      "Epoch 23/30\n",
      "1438/1438 [==============================] - 7s 5ms/step - loss: 1.1199 - sparse_categorical_accuracy: 0.6248 - mcc_metric: 0.0615 - val_loss: 1.0627 - val_sparse_categorical_accuracy: 0.4892 - val_mcc_metric: 0.1145\n",
      "Epoch 24/30\n",
      "1438/1438 [==============================] - 8s 5ms/step - loss: 1.1172 - sparse_categorical_accuracy: 0.6246 - mcc_metric: 0.0616 - val_loss: 1.0617 - val_sparse_categorical_accuracy: 0.4911 - val_mcc_metric: 0.1158\n",
      "Epoch 25/30\n",
      "1438/1438 [==============================] - 8s 5ms/step - loss: 1.1229 - sparse_categorical_accuracy: 0.6252 - mcc_metric: 0.0625 - val_loss: 1.0590 - val_sparse_categorical_accuracy: 0.4907 - val_mcc_metric: 0.1123\n",
      "Epoch 26/30\n",
      "1438/1438 [==============================] - 8s 5ms/step - loss: 1.1159 - sparse_categorical_accuracy: 0.6249 - mcc_metric: 0.0625 - val_loss: 1.0595 - val_sparse_categorical_accuracy: 0.4944 - val_mcc_metric: 0.1170\n",
      "Epoch 27/30\n",
      "1438/1438 [==============================] - 7s 5ms/step - loss: 1.1227 - sparse_categorical_accuracy: 0.6260 - mcc_metric: 0.0638 - val_loss: 1.0572 - val_sparse_categorical_accuracy: 0.4938 - val_mcc_metric: 0.1153\n",
      "Epoch 28/30\n",
      "1438/1438 [==============================] - 8s 5ms/step - loss: 1.1155 - sparse_categorical_accuracy: 0.6254 - mcc_metric: 0.0629 - val_loss: 1.0579 - val_sparse_categorical_accuracy: 0.4952 - val_mcc_metric: 0.1160\n",
      "Epoch 29/30\n",
      "1438/1438 [==============================] - 8s 6ms/step - loss: 1.1205 - sparse_categorical_accuracy: 0.6259 - mcc_metric: 0.0630 - val_loss: 1.0555 - val_sparse_categorical_accuracy: 0.4951 - val_mcc_metric: 0.1155\n",
      "Epoch 30/30\n",
      "1438/1438 [==============================] - 9s 6ms/step - loss: 1.1173 - sparse_categorical_accuracy: 0.6259 - mcc_metric: 0.0629 - val_loss: 1.0547 - val_sparse_categorical_accuracy: 0.4969 - val_mcc_metric: 0.1169\n",
      "Epoch 1/30\n",
      "2094/2094 [==============================] - 12s 6ms/step - loss: 1.1940 - sparse_categorical_accuracy: 0.6152 - mcc_metric: 0.1022 - val_loss: 1.4139 - val_sparse_categorical_accuracy: 0.4571 - val_mcc_metric: 0.1209\n",
      "Epoch 2/30\n",
      "2094/2094 [==============================] - 12s 6ms/step - loss: 1.2371 - sparse_categorical_accuracy: 0.6171 - mcc_metric: 0.1031 - val_loss: 1.4020 - val_sparse_categorical_accuracy: 0.4388 - val_mcc_metric: 0.1560\n",
      "Epoch 3/30\n",
      "2094/2094 [==============================] - 12s 6ms/step - loss: 1.2160 - sparse_categorical_accuracy: 0.6141 - mcc_metric: 0.1020 - val_loss: 1.4161 - val_sparse_categorical_accuracy: 0.4972 - val_mcc_metric: 0.1082\n",
      "Epoch 4/30\n",
      "2094/2094 [==============================] - 12s 6ms/step - loss: 1.2003 - sparse_categorical_accuracy: 0.6187 - mcc_metric: 0.1030 - val_loss: 1.3726 - val_sparse_categorical_accuracy: 0.4474 - val_mcc_metric: 0.1306\n",
      "Epoch 5/30\n",
      "2094/2094 [==============================] - 12s 6ms/step - loss: 1.2082 - sparse_categorical_accuracy: 0.6154 - mcc_metric: 0.1029 - val_loss: 1.4840 - val_sparse_categorical_accuracy: 0.4935 - val_mcc_metric: 0.1013\n",
      "Epoch 6/30\n",
      "2094/2094 [==============================] - 12s 6ms/step - loss: 1.1913 - sparse_categorical_accuracy: 0.6200 - mcc_metric: 0.1042 - val_loss: 1.3852 - val_sparse_categorical_accuracy: 0.4512 - val_mcc_metric: 0.1251\n",
      "Epoch 7/30\n",
      "2094/2094 [==============================] - 11s 5ms/step - loss: 1.2093 - sparse_categorical_accuracy: 0.6159 - mcc_metric: 0.1037 - val_loss: 1.4601 - val_sparse_categorical_accuracy: 0.4938 - val_mcc_metric: 0.1021\n",
      "Epoch 8/30\n",
      "2094/2094 [==============================] - 12s 6ms/step - loss: 1.1953 - sparse_categorical_accuracy: 0.6191 - mcc_metric: 0.1032 - val_loss: 1.3799 - val_sparse_categorical_accuracy: 0.4514 - val_mcc_metric: 0.1239\n",
      "Epoch 9/30\n",
      "2094/2094 [==============================] - 12s 6ms/step - loss: 1.2098 - sparse_categorical_accuracy: 0.6161 - mcc_metric: 0.1041 - val_loss: 1.4702 - val_sparse_categorical_accuracy: 0.4945 - val_mcc_metric: 0.1010\n"
     ]
    }
   ],
   "source": [
    "linear_models = {}\n",
    "\n",
    "for name in single_gens.keys():\n",
    "\n",
    "    linear = tf.keras.Sequential([\n",
    "        layers.Dense(units=3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # weights = get_class_weights(split_dfs, name)\n",
    "    history = compile_and_fit(linear, single_gens[name], lr=0.08, max_epochs=30, weights=None)\n",
    "\n",
    "    linear_models.update({f'linear_{name}' : linear})\n",
    "    train_performance[f'linear_{name}'] = linear.evaluate(single_gens[name].train, verbose=False)\n",
    "    val_performance[f'linear_{name}'] = linear.evaluate(single_gens[name].valid, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Baseline_AAPL': [nan, 0.0, 0.22320400178432465],\n",
       " 'Baseline_GOOG': [nan, 0.0, 0.215257465839386],\n",
       " 'Baseline_QCOM': [nan, 0.0, 0.21873155236244202],\n",
       " 'Baseline_TSLA': [nan, 0.0, 0.20606866478919983],\n",
       " 'linear_AAPL': [1.5238393545150757, 0.42958125472068787, 0.08913545310497284],\n",
       " 'linear_GOOG': [1.3434151411056519, 0.3188811242580414, 0.015764497220516205],\n",
       " 'linear_QCOM': [1.0547120571136475, 0.4968701899051666, 0.11689107865095139],\n",
       " 'linear_TSLA': [1.4702140092849731, 0.49448660016059875, 0.10098537802696228]}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use learning rate schuler to warmpup Transformer learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch, lr, warmup_epochs=15, decay_epochs=100, initial_lr=1e-6, base_lr=1e-3, min_lr=5e-5):\n",
    "    if epoch <= warmup_epochs:\n",
    "        pct = epoch / warmup_epochs\n",
    "        return ((base_lr - initial_lr) * pct) + initial_lr\n",
    "\n",
    "    if epoch > warmup_epochs and epoch < warmup_epochs+decay_epochs:\n",
    "        pct = 1 - ((epoch - warmup_epochs) / decay_epochs)\n",
    "        return ((base_lr - min_lr) * pct) + min_lr\n",
    "\n",
    "    return min_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2171/2171 [==============================] - 61s 27ms/step - loss: 1.0401 - sparse_categorical_accuracy: 0.5115 - mcc_metric: -0.0055 - val_loss: 1.0321 - val_sparse_categorical_accuracy: 0.5242 - val_mcc_metric: -0.0059 - lr: 1.0000e-06\n",
      "Epoch 2/30\n",
      "2171/2171 [==============================] - 60s 28ms/step - loss: 0.8313 - sparse_categorical_accuracy: 0.6434 - mcc_metric: 0.0215 - val_loss: 0.9486 - val_sparse_categorical_accuracy: 0.5499 - val_mcc_metric: 0.1061 - lr: 6.7600e-05\n",
      "Epoch 3/30\n",
      "2171/2171 [==============================] - 60s 28ms/step - loss: 0.8075 - sparse_categorical_accuracy: 0.6517 - mcc_metric: 0.0899 - val_loss: 0.9840 - val_sparse_categorical_accuracy: 0.5304 - val_mcc_metric: 0.1597 - lr: 1.3420e-04\n",
      "Epoch 4/30\n",
      "2171/2171 [==============================] - 60s 27ms/step - loss: 0.7978 - sparse_categorical_accuracy: 0.6568 - mcc_metric: 0.1129 - val_loss: 0.9914 - val_sparse_categorical_accuracy: 0.5293 - val_mcc_metric: 0.1765 - lr: 2.0080e-04\n",
      "Epoch 5/30\n",
      "2171/2171 [==============================] - 59s 27ms/step - loss: 0.7910 - sparse_categorical_accuracy: 0.6589 - mcc_metric: 0.1218 - val_loss: 0.9938 - val_sparse_categorical_accuracy: 0.5215 - val_mcc_metric: 0.1774 - lr: 2.6740e-04\n",
      "Epoch 6/30\n",
      "2171/2171 [==============================] - 60s 28ms/step - loss: 0.7849 - sparse_categorical_accuracy: 0.6609 - mcc_metric: 0.1291 - val_loss: 0.9865 - val_sparse_categorical_accuracy: 0.5202 - val_mcc_metric: 0.1875 - lr: 3.3400e-04\n",
      "Epoch 7/30\n",
      "2171/2171 [==============================] - 59s 27ms/step - loss: 0.7793 - sparse_categorical_accuracy: 0.6633 - mcc_metric: 0.1369 - val_loss: 0.9797 - val_sparse_categorical_accuracy: 0.5291 - val_mcc_metric: 0.1964 - lr: 4.0060e-04\n",
      "Epoch 1/30\n",
      "1068/1068 [==============================] - 27s 24ms/step - loss: 1.0832 - sparse_categorical_accuracy: 0.4206 - mcc_metric: 0.0128 - val_loss: 1.0708 - val_sparse_categorical_accuracy: 0.5131 - val_mcc_metric: -0.0064 - lr: 1.0000e-06\n",
      "Epoch 2/30\n",
      "1068/1068 [==============================] - 25s 23ms/step - loss: 0.8059 - sparse_categorical_accuracy: 0.7056 - mcc_metric: -2.4313e-04 - val_loss: 0.9866 - val_sparse_categorical_accuracy: 0.6058 - val_mcc_metric: -4.0781e-04 - lr: 6.7600e-05\n",
      "Epoch 3/30\n",
      "1068/1068 [==============================] - 25s 23ms/step - loss: 0.7911 - sparse_categorical_accuracy: 0.7072 - mcc_metric: 0.0035 - val_loss: 1.0005 - val_sparse_categorical_accuracy: 0.5611 - val_mcc_metric: 0.0124 - lr: 1.3420e-04\n",
      "Epoch 4/30\n",
      "1068/1068 [==============================] - 25s 23ms/step - loss: 0.7859 - sparse_categorical_accuracy: 0.7075 - mcc_metric: 0.0149 - val_loss: 1.0105 - val_sparse_categorical_accuracy: 0.5311 - val_mcc_metric: 0.0181 - lr: 2.0080e-04\n",
      "Epoch 5/30\n",
      "1068/1068 [==============================] - 25s 23ms/step - loss: 0.7803 - sparse_categorical_accuracy: 0.7069 - mcc_metric: 0.0222 - val_loss: 1.0108 - val_sparse_categorical_accuracy: 0.5306 - val_mcc_metric: 0.0184 - lr: 2.6740e-04\n",
      "Epoch 6/30\n",
      "1068/1068 [==============================] - 25s 23ms/step - loss: 0.7759 - sparse_categorical_accuracy: 0.7070 - mcc_metric: 0.0275 - val_loss: 1.0021 - val_sparse_categorical_accuracy: 0.5363 - val_mcc_metric: 0.0252 - lr: 3.3400e-04\n",
      "Epoch 7/30\n",
      "1068/1068 [==============================] - 25s 23ms/step - loss: 0.7710 - sparse_categorical_accuracy: 0.7063 - mcc_metric: 0.0298 - val_loss: 0.9955 - val_sparse_categorical_accuracy: 0.5437 - val_mcc_metric: 0.0418 - lr: 4.0060e-04\n",
      "Epoch 1/30\n",
      "1437/1437 [==============================] - 37s 25ms/step - loss: 1.0215 - sparse_categorical_accuracy: 0.6104 - mcc_metric: -0.0019 - val_loss: 1.0244 - val_sparse_categorical_accuracy: 0.5962 - val_mcc_metric: 0.0012 - lr: 1.0000e-06\n",
      "Epoch 2/30\n",
      "1437/1437 [==============================] - 36s 25ms/step - loss: 0.7977 - sparse_categorical_accuracy: 0.6893 - mcc_metric: -0.0010 - val_loss: 0.9422 - val_sparse_categorical_accuracy: 0.5988 - val_mcc_metric: 0.0000e+00 - lr: 6.7600e-05\n",
      "Epoch 3/30\n",
      "1437/1437 [==============================] - 36s 25ms/step - loss: 0.7879 - sparse_categorical_accuracy: 0.6901 - mcc_metric: 0.0011 - val_loss: 0.9381 - val_sparse_categorical_accuracy: 0.5980 - val_mcc_metric: -0.0032 - lr: 1.3420e-04\n",
      "Epoch 4/30\n",
      "1437/1437 [==============================] - 37s 25ms/step - loss: 0.7823 - sparse_categorical_accuracy: 0.6915 - mcc_metric: 0.0126 - val_loss: 0.9303 - val_sparse_categorical_accuracy: 0.6005 - val_mcc_metric: 0.0187 - lr: 2.0080e-04\n",
      "Epoch 5/30\n",
      "1437/1437 [==============================] - 37s 25ms/step - loss: 0.7762 - sparse_categorical_accuracy: 0.6930 - mcc_metric: 0.0284 - val_loss: 0.9263 - val_sparse_categorical_accuracy: 0.6016 - val_mcc_metric: 0.0379 - lr: 2.6740e-04\n",
      "Epoch 6/30\n",
      "1437/1437 [==============================] - 36s 25ms/step - loss: 0.7717 - sparse_categorical_accuracy: 0.6931 - mcc_metric: 0.0348 - val_loss: 0.9236 - val_sparse_categorical_accuracy: 0.6049 - val_mcc_metric: 0.0573 - lr: 3.3400e-04\n",
      "Epoch 7/30\n",
      "1437/1437 [==============================] - 36s 25ms/step - loss: 0.7695 - sparse_categorical_accuracy: 0.6945 - mcc_metric: 0.0459 - val_loss: 0.9240 - val_sparse_categorical_accuracy: 0.6035 - val_mcc_metric: 0.0575 - lr: 4.0060e-04\n",
      "Epoch 8/30\n",
      "1437/1437 [==============================] - 36s 25ms/step - loss: 0.7683 - sparse_categorical_accuracy: 0.6951 - mcc_metric: 0.0486 - val_loss: 0.9224 - val_sparse_categorical_accuracy: 0.6079 - val_mcc_metric: 0.0676 - lr: 4.6720e-04\n",
      "Epoch 9/30\n",
      "1437/1437 [==============================] - 36s 25ms/step - loss: 0.7659 - sparse_categorical_accuracy: 0.6961 - mcc_metric: 0.0541 - val_loss: 0.9242 - val_sparse_categorical_accuracy: 0.6067 - val_mcc_metric: 0.0742 - lr: 5.3380e-04\n",
      "Epoch 10/30\n",
      "1437/1437 [==============================] - 36s 25ms/step - loss: 0.7648 - sparse_categorical_accuracy: 0.6973 - mcc_metric: 0.0579 - val_loss: 0.9400 - val_sparse_categorical_accuracy: 0.5912 - val_mcc_metric: 0.0796 - lr: 6.0040e-04\n",
      "Epoch 11/30\n",
      "1437/1437 [==============================] - 36s 25ms/step - loss: 0.7631 - sparse_categorical_accuracy: 0.6974 - mcc_metric: 0.0595 - val_loss: 0.9169 - val_sparse_categorical_accuracy: 0.6094 - val_mcc_metric: 0.0815 - lr: 6.6700e-04\n",
      "Epoch 12/30\n",
      "1437/1437 [==============================] - 36s 25ms/step - loss: 0.7618 - sparse_categorical_accuracy: 0.6965 - mcc_metric: 0.0657 - val_loss: 0.9241 - val_sparse_categorical_accuracy: 0.6095 - val_mcc_metric: 0.0941 - lr: 7.3360e-04\n",
      "Epoch 13/30\n",
      "1437/1437 [==============================] - 36s 25ms/step - loss: 0.7587 - sparse_categorical_accuracy: 0.6982 - mcc_metric: 0.0649 - val_loss: 0.9214 - val_sparse_categorical_accuracy: 0.6106 - val_mcc_metric: 0.0884 - lr: 8.0020e-04\n",
      "Epoch 14/30\n",
      "1437/1437 [==============================] - 36s 25ms/step - loss: 0.7567 - sparse_categorical_accuracy: 0.6991 - mcc_metric: 0.0706 - val_loss: 0.9207 - val_sparse_categorical_accuracy: 0.6098 - val_mcc_metric: 0.0902 - lr: 8.6680e-04\n",
      "Epoch 15/30\n",
      "1437/1437 [==============================] - 36s 25ms/step - loss: 0.7577 - sparse_categorical_accuracy: 0.6981 - mcc_metric: 0.0723 - val_loss: 0.9215 - val_sparse_categorical_accuracy: 0.6046 - val_mcc_metric: 0.0819 - lr: 9.3340e-04\n",
      "Epoch 16/30\n",
      "1437/1437 [==============================] - 36s 25ms/step - loss: 0.7569 - sparse_categorical_accuracy: 0.6976 - mcc_metric: 0.0715 - val_loss: 0.9204 - val_sparse_categorical_accuracy: 0.6057 - val_mcc_metric: 0.0870 - lr: 0.0010\n",
      "Epoch 1/30\n",
      "2093/2093 [==============================] - 58s 27ms/step - loss: 1.0311 - sparse_categorical_accuracy: 0.5749 - mcc_metric: 0.0023 - val_loss: 1.0239 - val_sparse_categorical_accuracy: 0.5733 - val_mcc_metric: 0.0015 - lr: 1.0000e-06\n",
      "Epoch 2/30\n",
      "2093/2093 [==============================] - 57s 27ms/step - loss: 0.8780 - sparse_categorical_accuracy: 0.6243 - mcc_metric: 0.0045 - val_loss: 0.9275 - val_sparse_categorical_accuracy: 0.5558 - val_mcc_metric: 0.0103 - lr: 6.7600e-05\n",
      "Epoch 3/30\n",
      "2093/2093 [==============================] - 57s 27ms/step - loss: 0.8353 - sparse_categorical_accuracy: 0.6319 - mcc_metric: 0.0604 - val_loss: 0.9173 - val_sparse_categorical_accuracy: 0.5737 - val_mcc_metric: 0.1320 - lr: 1.3420e-04\n",
      "Epoch 4/30\n",
      "2093/2093 [==============================] - 57s 27ms/step - loss: 0.8177 - sparse_categorical_accuracy: 0.6418 - mcc_metric: 0.1201 - val_loss: 0.9227 - val_sparse_categorical_accuracy: 0.5707 - val_mcc_metric: 0.1510 - lr: 2.0080e-04\n",
      "Epoch 5/30\n",
      "2093/2093 [==============================] - 57s 27ms/step - loss: 0.8079 - sparse_categorical_accuracy: 0.6485 - mcc_metric: 0.1342 - val_loss: 0.9228 - val_sparse_categorical_accuracy: 0.5711 - val_mcc_metric: 0.1567 - lr: 2.6740e-04\n",
      "Epoch 6/30\n",
      "2093/2093 [==============================] - 58s 28ms/step - loss: 0.8004 - sparse_categorical_accuracy: 0.6511 - mcc_metric: 0.1434 - val_loss: 0.9223 - val_sparse_categorical_accuracy: 0.5690 - val_mcc_metric: 0.1669 - lr: 3.3400e-04\n",
      "Epoch 7/30\n",
      "2093/2093 [==============================] - 57s 27ms/step - loss: 0.7942 - sparse_categorical_accuracy: 0.6541 - mcc_metric: 0.1511 - val_loss: 0.9262 - val_sparse_categorical_accuracy: 0.5662 - val_mcc_metric: 0.1777 - lr: 4.0060e-04\n",
      "Epoch 8/30\n",
      "2093/2093 [==============================] - 58s 28ms/step - loss: 0.7910 - sparse_categorical_accuracy: 0.6557 - mcc_metric: 0.1542 - val_loss: 0.9300 - val_sparse_categorical_accuracy: 0.5651 - val_mcc_metric: 0.1782 - lr: 4.6720e-04\n"
     ]
    }
   ],
   "source": [
    "transformer_models = {}\n",
    "\n",
    "for name in single_gens.keys():\n",
    "\n",
    "    transformer_model = TransformerModel(\n",
    "                                    n_heads=2,\n",
    "                                    d_model=512,\n",
    "                                    ff_dim=256,\n",
    "                                    num_transformer_blocks=1,\n",
    "                                    mlp_units=[256],\n",
    "                                    n_outputs=3,\n",
    "                                    dropout=0.1,\n",
    "                                    mlp_dropout=0.1)\n",
    "\n",
    "    # weights = get_class_weights(split_dfs, name)\n",
    "    history = compile_and_fit(transformer_model, window_gens[name], lr=1e-6, max_epochs=30, \n",
    "                          lr_scheduler=lr_scheduler, patience=5)\n",
    "\n",
    "    transformer_models.update({f'transformer_{name}' : transformer_model})\n",
    "    train_performance[f'transformer_{name}'] = transformer_model.evaluate(window_gens[name].train, verbose=False)\n",
    "    val_performance[f'transformer_{name}'] = transformer_model.evaluate(window_gens[name].valid, verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2171/2171 [==============================] - 61s 28ms/step - loss: 0.8685 - sparse_categorical_accuracy: 0.6419 - mcc_metric: 0.0398 - val_loss: 1.0020 - val_sparse_categorical_accuracy: 0.5372 - val_mcc_metric: 0.1200\n",
      "Epoch 2/30\n",
      "2171/2171 [==============================] - 60s 28ms/step - loss: 0.8480 - sparse_categorical_accuracy: 0.6521 - mcc_metric: 0.0703 - val_loss: 0.9761 - val_sparse_categorical_accuracy: 0.5519 - val_mcc_metric: 0.1673\n",
      "Epoch 3/30\n",
      "2171/2171 [==============================] - 61s 28ms/step - loss: 0.8344 - sparse_categorical_accuracy: 0.6534 - mcc_metric: 0.0791 - val_loss: 0.9937 - val_sparse_categorical_accuracy: 0.5489 - val_mcc_metric: 0.1739\n",
      "Epoch 4/30\n",
      "2171/2171 [==============================] - 59s 27ms/step - loss: 0.8417 - sparse_categorical_accuracy: 0.6532 - mcc_metric: 0.0810 - val_loss: 1.0224 - val_sparse_categorical_accuracy: 0.5388 - val_mcc_metric: 0.1835\n",
      "Epoch 5/30\n",
      "2171/2171 [==============================] - 59s 27ms/step - loss: 0.8414 - sparse_categorical_accuracy: 0.6533 - mcc_metric: 0.0764 - val_loss: 0.9894 - val_sparse_categorical_accuracy: 0.5391 - val_mcc_metric: 0.1465\n",
      "Epoch 6/30\n",
      "2171/2171 [==============================] - 59s 27ms/step - loss: 0.8482 - sparse_categorical_accuracy: 0.6500 - mcc_metric: 0.0608 - val_loss: 1.0098 - val_sparse_categorical_accuracy: 0.5340 - val_mcc_metric: 0.1510\n",
      "Epoch 7/30\n",
      "2171/2171 [==============================] - 59s 27ms/step - loss: 0.8450 - sparse_categorical_accuracy: 0.6525 - mcc_metric: 0.0725 - val_loss: 1.0053 - val_sparse_categorical_accuracy: 0.5261 - val_mcc_metric: 0.1291\n",
      "Epoch 1/30\n",
      "1068/1068 [==============================] - 26s 23ms/step - loss: 0.7924 - sparse_categorical_accuracy: 0.7068 - mcc_metric: 0.0043 - val_loss: 0.9534 - val_sparse_categorical_accuracy: 0.6069 - val_mcc_metric: 0.0060\n",
      "Epoch 2/30\n",
      "1068/1068 [==============================] - 25s 23ms/step - loss: 0.8025 - sparse_categorical_accuracy: 0.7073 - mcc_metric: 0.0031 - val_loss: 0.9560 - val_sparse_categorical_accuracy: 0.6064 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1068/1068 [==============================] - 24s 23ms/step - loss: 0.7998 - sparse_categorical_accuracy: 0.7079 - mcc_metric: 0.0000e+00 - val_loss: 0.9565 - val_sparse_categorical_accuracy: 0.6064 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1068/1068 [==============================] - 26s 24ms/step - loss: 0.8000 - sparse_categorical_accuracy: 0.7079 - mcc_metric: 0.0000e+00 - val_loss: 0.9565 - val_sparse_categorical_accuracy: 0.6064 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1068/1068 [==============================] - 26s 24ms/step - loss: 0.8000 - sparse_categorical_accuracy: 0.7079 - mcc_metric: 0.0000e+00 - val_loss: 0.9565 - val_sparse_categorical_accuracy: 0.6064 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1068/1068 [==============================] - 26s 24ms/step - loss: 0.8000 - sparse_categorical_accuracy: 0.7079 - mcc_metric: 0.0000e+00 - val_loss: 0.9565 - val_sparse_categorical_accuracy: 0.6064 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 1/30\n",
      "1437/1437 [==============================] - 40s 27ms/step - loss: 0.8096 - sparse_categorical_accuracy: 0.6897 - mcc_metric: -1.5396e-04 - val_loss: 0.9558 - val_sparse_categorical_accuracy: 0.5988 - val_mcc_metric: 4.4921e-04\n",
      "Epoch 2/30\n",
      "1437/1437 [==============================] - 38s 27ms/step - loss: 0.8075 - sparse_categorical_accuracy: 0.6897 - mcc_metric: 1.1746e-04 - val_loss: 0.9559 - val_sparse_categorical_accuracy: 0.5988 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1437/1437 [==============================] - 38s 27ms/step - loss: 0.8076 - sparse_categorical_accuracy: 0.6897 - mcc_metric: 0.0000e+00 - val_loss: 0.9559 - val_sparse_categorical_accuracy: 0.5988 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1437/1437 [==============================] - 36s 25ms/step - loss: 0.8076 - sparse_categorical_accuracy: 0.6897 - mcc_metric: 0.0000e+00 - val_loss: 0.9559 - val_sparse_categorical_accuracy: 0.5988 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1437/1437 [==============================] - 36s 25ms/step - loss: 0.8076 - sparse_categorical_accuracy: 0.6897 - mcc_metric: 0.0000e+00 - val_loss: 0.9559 - val_sparse_categorical_accuracy: 0.5988 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1437/1437 [==============================] - 36s 25ms/step - loss: 0.8076 - sparse_categorical_accuracy: 0.6897 - mcc_metric: 0.0000e+00 - val_loss: 0.9559 - val_sparse_categorical_accuracy: 0.5988 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 1/30\n",
      "2093/2093 [==============================] - 57s 27ms/step - loss: 0.9044 - sparse_categorical_accuracy: 0.6232 - mcc_metric: 0.0000e+00 - val_loss: 0.9897 - val_sparse_categorical_accuracy: 0.5733 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 2/30\n",
      "2093/2093 [==============================] - 56s 27ms/step - loss: 0.9059 - sparse_categorical_accuracy: 0.6232 - mcc_metric: 0.0000e+00 - val_loss: 0.9896 - val_sparse_categorical_accuracy: 0.5733 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 3/30\n",
      "2093/2093 [==============================] - 56s 27ms/step - loss: 0.9059 - sparse_categorical_accuracy: 0.6232 - mcc_metric: 0.0000e+00 - val_loss: 0.9896 - val_sparse_categorical_accuracy: 0.5733 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 4/30\n",
      "2093/2093 [==============================] - 56s 27ms/step - loss: 0.9059 - sparse_categorical_accuracy: 0.6232 - mcc_metric: 0.0000e+00 - val_loss: 0.9896 - val_sparse_categorical_accuracy: 0.5733 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 5/30\n",
      "2093/2093 [==============================] - 55s 26ms/step - loss: 0.9059 - sparse_categorical_accuracy: 0.6232 - mcc_metric: 0.0000e+00 - val_loss: 0.9896 - val_sparse_categorical_accuracy: 0.5733 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 6/30\n",
      "2093/2093 [==============================] - 56s 27ms/step - loss: 0.9059 - sparse_categorical_accuracy: 0.6232 - mcc_metric: 0.0000e+00 - val_loss: 0.9896 - val_sparse_categorical_accuracy: 0.5733 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 7/30\n",
      "2093/2093 [==============================] - 56s 27ms/step - loss: 0.9059 - sparse_categorical_accuracy: 0.6232 - mcc_metric: 0.0000e+00 - val_loss: 0.9896 - val_sparse_categorical_accuracy: 0.5733 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 8/30\n",
      "2093/2093 [==============================] - 55s 27ms/step - loss: 0.9059 - sparse_categorical_accuracy: 0.6232 - mcc_metric: 0.0000e+00 - val_loss: 0.9896 - val_sparse_categorical_accuracy: 0.5733 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 9/30\n",
      "2093/2093 [==============================] - 56s 27ms/step - loss: 0.9059 - sparse_categorical_accuracy: 0.6232 - mcc_metric: 0.0000e+00 - val_loss: 0.9896 - val_sparse_categorical_accuracy: 0.5733 - val_mcc_metric: 0.0000e+00\n",
      "Epoch 10/30\n",
      "2093/2093 [==============================] - 56s 27ms/step - loss: 0.9059 - sparse_categorical_accuracy: 0.6232 - mcc_metric: 0.0000e+00 - val_loss: 0.9896 - val_sparse_categorical_accuracy: 0.5733 - val_mcc_metric: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "lstm_models = {}\n",
    "\n",
    "for name in single_gens.keys():\n",
    "\n",
    "    lstm_model = tf.keras.models.Sequential([\n",
    "        # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "        # layers.LSTM(25, dropout=0.0, return_sequences=True),\n",
    "        layers.LSTM(25, dropout=0.0),\n",
    "        # Shape => [batch, time, features]\n",
    "        # layers.TimeDistributed(layers.Dense(units=3, activation='softmax')),\n",
    "        layers.Dense(units=3, activation='softmax'),\n",
    "        layers.Reshape([1, -1])\n",
    "    ])\n",
    "\n",
    "    # weights = get_class_weights(split_dfs, name)\n",
    "    history = compile_and_fit(transformer_model, window_gens[name], lr=0.005, max_epochs=30, \n",
    "                              patience=5)\n",
    "\n",
    "    lstm_models.update({f'lstm_{name}' : lstm_models})\n",
    "    train_performance[f'lstm_{name}'] = lstm_models.evaluate(window_gens[name].train, verbose=False)\n",
    "    val_performance[f'lstm_{name}'] = lstm_models.evaluate(window_gens[name].valid, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Baseline_AAPL': [nan, 0.0, 0.17250658571720123],\n",
       " 'Baseline_GOOG': [nan, 0.0, 0.17368914186954498],\n",
       " 'Baseline_QCOM': [nan, 0.0, 0.16974611580371857],\n",
       " 'Baseline_TSLA': [nan, 0.0, 0.18433701992034912],\n",
       " 'linear_AAPL': [2.0645980834960938, 0.39052852988243103, 0.05672554671764374],\n",
       " 'linear_GOOG': [1.6996376514434814, 0.2846441864967346, 0.022803664207458496],\n",
       " 'linear_QCOM': [1.0521388053894043, 0.5544300675392151, 0.09147047996520996],\n",
       " 'linear_TSLA': [1.7513982057571411, 0.4700683653354645, 0.08654278516769409],\n",
       " 'transformer_AAPL': [0.9866639971733093,\n",
       "  0.49967238306999207,\n",
       "  0.19455310702323914],\n",
       " 'transformer_GOOG': [0.8812099695205688,\n",
       "  0.6865711212158203,\n",
       "  0.07174509763717651],\n",
       " 'transformer_QCOM': [0.8338237404823303,\n",
       "  0.6866649389266968,\n",
       "  0.11423670500516891],\n",
       " 'transformer_TSLA': [0.9290779829025269,\n",
       "  0.5608723163604736,\n",
       "  0.20469708740711212],\n",
       " 'lstm_AAPL': [0.9899654388427734, 0.5537832975387573, 0.1464715301990509],\n",
       " 'lstm_GOOG': [0.8691303730010986, 0.7079162001609802, 0.0],\n",
       " 'lstm_QCOM': [0.8734530210494995, 0.6897081136703491, 0.0],\n",
       " 'lstm_TSLA': [0.954899787902832, 0.6232315301895142, 0.0]}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Baseline_AAPL': [nan, 0.0, 0.22320400178432465],\n",
       " 'Baseline_GOOG': [nan, 0.0, 0.215257465839386],\n",
       " 'Baseline_QCOM': [nan, 0.0, 0.21873155236244202],\n",
       " 'Baseline_TSLA': [nan, 0.0, 0.20606866478919983],\n",
       " 'linear_AAPL': [1.5238393545150757, 0.42958125472068787, 0.08913545310497284],\n",
       " 'linear_GOOG': [1.3434151411056519, 0.3188811242580414, 0.015764497220516205],\n",
       " 'linear_QCOM': [1.0547120571136475, 0.4968701899051666, 0.11689107865095139],\n",
       " 'linear_TSLA': [1.4702140092849731, 0.49448660016059875, 0.10098537802696228],\n",
       " 'transformer_AAPL': [0.9796975255012512,\n",
       "  0.5290548205375671,\n",
       "  0.19643597304821014],\n",
       " 'transformer_GOOG': [0.9954694509506226,\n",
       "  0.5436605215072632,\n",
       "  0.04179302975535393],\n",
       " 'transformer_QCOM': [0.9204387664794922,\n",
       "  0.605720579624176,\n",
       "  0.08696354180574417],\n",
       " 'transformer_TSLA': [0.9299902319908142,\n",
       "  0.5650826692581177,\n",
       "  0.17820467054843903],\n",
       " 'lstm_AAPL': [1.0053125619888306, 0.5261125564575195, 0.12908129394054413],\n",
       " 'lstm_GOOG': [0.9564542174339294, 0.6063569784164429, 0.0],\n",
       " 'lstm_QCOM': [0.9558749794960022, 0.5987673997879028, 0.0],\n",
       " 'lstm_TSLA': [0.989646852016449, 0.5732532143592834, 0.0]}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Classification Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get the predictions and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_preds(model, data_gen, threshold=0):\n",
    "    ''' Obtains truth labels and predictions for a model/data_gen pair '''\n",
    "    # get predictions\n",
    "    prediction_vectors = model.predict(data_gen)\n",
    "    predictions = tf.argmax(prediction_vectors, axis=-1)\n",
    "\n",
    "    # get labels\n",
    "    # labels = tf.concat([_labels for _, _labels, _ in data_gen], axis=0)\n",
    "    labels = tf.concat([_labels for _, _labels in data_gen], axis=0)\n",
    "    labels = tf.squeeze(labels, axis=-1)\n",
    "\n",
    "    if threshold > 0:\n",
    "        probs = tf.reduce_max(prediction_vectors, axis=-1)\n",
    "        locs = probs > threshold\n",
    "\n",
    "        predictions = predictions[locs]\n",
    "        labels = labels[locs]\n",
    "\n",
    "    return predictions, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2094/2094 [==============================] - 2s 1ms/step\n",
      "400/400 [==============================] - 0s 912us/step\n"
     ]
    }
   ],
   "source": [
    "base_train_preds, base_train_labels = get_label_preds(baseline, base_gen.train)\n",
    "base_valid_preds, base_valid_labels = get_label_preds(baseline, base_gen.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2172/2172 [==============================] - 3s 1ms/step\n",
      "407/407 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "linear_train_preds, linear_train_labels = get_label_preds(linear, \n",
    "                                                          single_gens['AAPL'].train,\n",
    "                                                          threshold=0.)\n",
    "linear_valid_preds, linear_valid_labels = get_label_preds(linear, \n",
    "                                                          single_gens['AAPL'].valid,\n",
    "                                                          threshold=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 4817,  2797,  4374],\n",
       "       [ 9458, 21368, 14613],\n",
       "       [ 3955,  2719,  5392]])>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.confusion_matrix(tf.squeeze(linear_train_labels), linear_train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 824,  736, 1345],\n",
       "       [1178, 3445, 2599],\n",
       "       [ 433,  745, 1710]])>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.confusion_matrix(tf.squeeze(linear_valid_labels), linear_valid_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2171/2171 [==============================] - 9s 4ms/step\n",
      "406/406 [==============================] - 2s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "xformer_train_preds, xformer_train_labels = get_label_preds(transformer_model, \n",
    "                                                            window_gens['AAPL'].train,\n",
    "                                                            threshold=0.)\n",
    "xformer_valid_preds, xformer_valid_labels = get_label_preds(transformer_model, \n",
    "                                                            window_gens['AAPL'].valid,\n",
    "                                                            threshold=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.confusion_matrix(tf.squeeze(xformer_train_labels), xformer_train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.confusion_matrix(tf.squeeze(xformer_valid_labels), xformer_valid_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_train_preds, lstm_train_labels = get_label_preds(lstm_model, \n",
    "                                                      window_gens['AAPL'].train,\n",
    "                                                      threshold=0.)\n",
    "lstm_valid_preds, lstm_valid_labels = get_label_preds(lstm_model, \n",
    "                                                      window_gens['AAPL'].valid,\n",
    "                                                      threshold=0.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b2da39daaaff30a84159e8452ba91acfc0bbd521fb66c6aa9941f847b87bd81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
