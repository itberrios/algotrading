{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Afternoon Trading Pipeline**\n",
    "\n",
    "In this notebook we will explore the basic pipeline for afternoon trading on 15min interval stock data. We will be working with a portfolio of highly correlated stocks: AAPL, GOOG, QCOM, and TSLA. These stock were highly correlated around Aug - Oct 2022. The stock dataset does not contains timestamps, prices and trading volume, but does not contin any target variables.\n",
    "- Timestamps &#8594; Interval\n",
    "- Open/Close/High/Low Prices &#8594; Ratio\n",
    "- Trading Volume &#8594; Ratio\n",
    "\n",
    " We will create the target variable by taking the midpoint of Open/Close prices for M future days and then averaging these values. This target variable is Oridnal and has 3 possible classes: \n",
    "- 0 - downward price movement\n",
    "- 1 - no change\n",
    "- 2 - upward price movement\n",
    "\n",
    "The price movements are derived by a threshold that is defined using the IQR method to detect outliers. Currently we use a limit of 1, and every Q1 outlier is classified as \"0 - downward price movement\", every Q3 outlier is classified as \"2 - upward price movement\", and all inliers are classified as: \"1 - no change\".\n",
    "\n",
    "For this problem we filter the data to only inlcude regular trading hours. Since afterhours trading effects the stock prices, we are interested in only training and predicting by using windows the occur sequentially (i.e. within the same trading day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "The main model we will be testing in this notebook is a Transformer Encoder. Typically a Transformer has an Encoder and Decoder portion, where the Encoder learns information about which parts of the input sequence are relevant to eachother. The Decoder does the opposite, it takes the continuouss representation learned by the Encoder and learns to generate an ordered output sequence. For the Time Series Classifiecation problem it is unecessary to include the Decoder, we can simply use the Encoder to learn relative correlations of the inputs and add a Vanilla Feed Forward Neural Network to the end of the Encoder Blocks to obtain the desired classification. [Source](https://userweb.cs.txstate.edu/~amk181/AIME_LSTM_Attention_vs_Transformer.pdf).\n",
    "\n",
    "The Transformer Encoder also relies on positional encoding in order to implement this, we will first project the input vectors into high dimensional space as done [here](https://arxiv.org/pdf/2010.02803.pdf), and then add the positional Encoding as done in the [original paper](https://arxiv.org/pdf/1706.03762.pdf).\n",
    "\n",
    "\n",
    "In order to compare how effective the Transformer is in modeling seuqential data, we will compare its results to:\n",
    "- Baseline Model (uses previous predictions)\n",
    "- Linear Model\n",
    "- Neural Network\n",
    "- LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Imports\n",
    "\n",
    "Get base dir for imports, this allows us to look in the main algotrading folder to import local modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath(os.path.join(os.path.abspath('..'), '..'))\n",
    "sys.path.append(BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import *\n",
    "from data_pipeline import *\n",
    "from window_generator import WindowGenerator\n",
    "from models.basic_transformer import TransformerModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure that GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data\n",
    "Place all stocks in a Dictionary of DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import re\n",
    "\n",
    "# get all data .csvs\n",
    "data_paths = glob(os.path.join(BASE_DIR, r'data\\raw\\*.csv'))\n",
    "\n",
    "# get stock DataFrames dict\n",
    "stock_dfs = get_stocks(data_paths, tgt_window=4, iqr_lim=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trading_times(df):\n",
    "    ''' Obtains a cleaned stock price DataFrame, with trading times ranging\n",
    "        from 9:30 - 4:00\n",
    "       '''\n",
    "    \n",
    "    # ensure that all trading times are sequential, pad missing data with NaNs\n",
    "    df = df.reindex(pd.date_range(df.index[0], df.index[-1], freq='15min'))\n",
    "       \n",
    "    # get regular trading times\n",
    "    dayofweek = df.index.dayofweek\n",
    "    hour = df.index.hour\n",
    "    minute = df.index.minute\n",
    "    \n",
    "    df = df.iloc[(dayofweek <= 4)                  # only get M-F\n",
    "                 & ~((hour == 9) & (minute < 30))  # remove less than 9:30\n",
    "                 & ((hour >= 9) & (hour <= 16))    # hours 9-16\n",
    "                 & ~((hour == 16) & (minute > 0))] # remove greater than 16:00\n",
    "    \n",
    "    # remove NaNs\n",
    "    df = df[~df.isna().all(axis=1)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in stock_dfs.keys():\n",
    "    df = stock_dfs[name]\n",
    "    # add filtered stock back to stock dict\n",
    "    stock_dfs[name] = get_trading_times(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place plots of number of each class for each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "for i, name in enumerate(stock_dfs.keys()):\n",
    "    # get plotting axes\n",
    "    ax = plt.subplot(2, 2, i + 1)\n",
    "\n",
    "    # get stock DataFrame\n",
    "    df = stock_dfs[name]\n",
    "\n",
    "    # compute class counts\n",
    "    down = np.sum(df.price_change == 0)\n",
    "    none = np.sum(df.price_change == 1)\n",
    "    up = np.sum(df.price_change == 2)\n",
    "\n",
    "    ax.barh([2.25], [0]) # expand to fit the legend\n",
    "    ax.barh([0], [down], height=0.4, edgecolor='k', label='num_downward')\n",
    "    ax.barh([1], [none], height=0.4, edgecolor='k', label='num_no_change')\n",
    "    ax.barh([2], [up], height=0.4, edgecolor='k', label='num_upward')\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel('Number of Samples')\n",
    "    ax.set_ylabel('Price Movement Class')\n",
    "    ax.legend();\n",
    "\n",
    "# set main title\n",
    "fig.suptitle('Number of training samples in each class', size=24)\n",
    "\n",
    "# add a bit of space\n",
    "fig.subplots_adjust(hspace=0.35);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUTURE -- Add more features \n",
    "Add functionalities to data_pipeline module\n",
    "- Price/Volume Differences\n",
    "- Time Encoding\n",
    "- Technical Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEW - Add Day of Week to features and remove later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in stock_dfs.keys():\n",
    "    df = stock_dfs[name]\n",
    "    df['dayofweek'] =  df.index.dayofweek\n",
    "\n",
    "    stock_dfs[name] = df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>price_trend</th>\n",
       "      <th>price_change</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-23 09:30:00</th>\n",
       "      <td>114.932978</td>\n",
       "      <td>114.992262</td>\n",
       "      <td>114.893455</td>\n",
       "      <td>114.972501</td>\n",
       "      <td>137430.0</td>\n",
       "      <td>-0.523458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23 09:45:00</th>\n",
       "      <td>115.002143</td>\n",
       "      <td>115.160235</td>\n",
       "      <td>114.152398</td>\n",
       "      <td>114.322248</td>\n",
       "      <td>5962724.0</td>\n",
       "      <td>-0.547765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23 10:00:00</th>\n",
       "      <td>114.330252</td>\n",
       "      <td>114.448821</td>\n",
       "      <td>113.994306</td>\n",
       "      <td>114.093015</td>\n",
       "      <td>3968090.0</td>\n",
       "      <td>-0.353101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23 10:15:00</th>\n",
       "      <td>114.083233</td>\n",
       "      <td>114.083233</td>\n",
       "      <td>113.411341</td>\n",
       "      <td>113.697883</td>\n",
       "      <td>4777513.0</td>\n",
       "      <td>-0.176532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23 10:30:00</th>\n",
       "      <td>113.698674</td>\n",
       "      <td>113.885617</td>\n",
       "      <td>113.371818</td>\n",
       "      <td>113.688002</td>\n",
       "      <td>3805439.0</td>\n",
       "      <td>-0.010190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23 10:45:00</th>\n",
       "      <td>113.678122</td>\n",
       "      <td>113.984425</td>\n",
       "      <td>113.450864</td>\n",
       "      <td>113.599075</td>\n",
       "      <td>2891741.0</td>\n",
       "      <td>0.041363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23 11:00:00</th>\n",
       "      <td>113.598977</td>\n",
       "      <td>113.796691</td>\n",
       "      <td>113.411341</td>\n",
       "      <td>113.668241</td>\n",
       "      <td>2857045.0</td>\n",
       "      <td>-0.012302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23 11:15:00</th>\n",
       "      <td>113.668241</td>\n",
       "      <td>113.944902</td>\n",
       "      <td>113.589195</td>\n",
       "      <td>113.865856</td>\n",
       "      <td>2297087.0</td>\n",
       "      <td>-0.235891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23 11:30:00</th>\n",
       "      <td>113.865856</td>\n",
       "      <td>113.895498</td>\n",
       "      <td>113.174203</td>\n",
       "      <td>113.495328</td>\n",
       "      <td>3448651.0</td>\n",
       "      <td>-0.256072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23 11:45:00</th>\n",
       "      <td>113.490387</td>\n",
       "      <td>113.529910</td>\n",
       "      <td>113.164322</td>\n",
       "      <td>113.317573</td>\n",
       "      <td>2394617.0</td>\n",
       "      <td>-0.077725</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23 12:00:00</th>\n",
       "      <td>113.312534</td>\n",
       "      <td>113.421222</td>\n",
       "      <td>112.917303</td>\n",
       "      <td>113.233487</td>\n",
       "      <td>3735942.0</td>\n",
       "      <td>0.035003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23 12:15:00</th>\n",
       "      <td>113.225188</td>\n",
       "      <td>113.618837</td>\n",
       "      <td>113.124799</td>\n",
       "      <td>113.455805</td>\n",
       "      <td>2648860.0</td>\n",
       "      <td>0.024331</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23 12:30:00</th>\n",
       "      <td>113.450963</td>\n",
       "      <td>113.599075</td>\n",
       "      <td>112.966707</td>\n",
       "      <td>113.124107</td>\n",
       "      <td>3295785.0</td>\n",
       "      <td>0.116000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23 12:45:00</th>\n",
       "      <td>113.120550</td>\n",
       "      <td>113.549672</td>\n",
       "      <td>113.060574</td>\n",
       "      <td>113.541471</td>\n",
       "      <td>2447232.0</td>\n",
       "      <td>0.147940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23 13:00:00</th>\n",
       "      <td>113.539791</td>\n",
       "      <td>113.678122</td>\n",
       "      <td>113.253249</td>\n",
       "      <td>113.460745</td>\n",
       "      <td>2571386.0</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Open        High         Low       Close  \\\n",
       "2020-10-23 09:30:00  114.932978  114.992262  114.893455  114.972501   \n",
       "2020-10-23 09:45:00  115.002143  115.160235  114.152398  114.322248   \n",
       "2020-10-23 10:00:00  114.330252  114.448821  113.994306  114.093015   \n",
       "2020-10-23 10:15:00  114.083233  114.083233  113.411341  113.697883   \n",
       "2020-10-23 10:30:00  113.698674  113.885617  113.371818  113.688002   \n",
       "2020-10-23 10:45:00  113.678122  113.984425  113.450864  113.599075   \n",
       "2020-10-23 11:00:00  113.598977  113.796691  113.411341  113.668241   \n",
       "2020-10-23 11:15:00  113.668241  113.944902  113.589195  113.865856   \n",
       "2020-10-23 11:30:00  113.865856  113.895498  113.174203  113.495328   \n",
       "2020-10-23 11:45:00  113.490387  113.529910  113.164322  113.317573   \n",
       "2020-10-23 12:00:00  113.312534  113.421222  112.917303  113.233487   \n",
       "2020-10-23 12:15:00  113.225188  113.618837  113.124799  113.455805   \n",
       "2020-10-23 12:30:00  113.450963  113.599075  112.966707  113.124107   \n",
       "2020-10-23 12:45:00  113.120550  113.549672  113.060574  113.541471   \n",
       "2020-10-23 13:00:00  113.539791  113.678122  113.253249  113.460745   \n",
       "\n",
       "                        Volume  price_trend  price_change  dayofweek  \n",
       "2020-10-23 09:30:00   137430.0    -0.523458           0.0          4  \n",
       "2020-10-23 09:45:00  5962724.0    -0.547765           0.0          4  \n",
       "2020-10-23 10:00:00  3968090.0    -0.353101           0.0          4  \n",
       "2020-10-23 10:15:00  4777513.0    -0.176532           0.0          4  \n",
       "2020-10-23 10:30:00  3805439.0    -0.010190           1.0          4  \n",
       "2020-10-23 10:45:00  2891741.0     0.041363           1.0          4  \n",
       "2020-10-23 11:00:00  2857045.0    -0.012302           1.0          4  \n",
       "2020-10-23 11:15:00  2297087.0    -0.235891           0.0          4  \n",
       "2020-10-23 11:30:00  3448651.0    -0.256072           0.0          4  \n",
       "2020-10-23 11:45:00  2394617.0    -0.077725           1.0          4  \n",
       "2020-10-23 12:00:00  3735942.0     0.035003           1.0          4  \n",
       "2020-10-23 12:15:00  2648860.0     0.024331           1.0          4  \n",
       "2020-10-23 12:30:00  3295785.0     0.116000           1.0          4  \n",
       "2020-10-23 12:45:00  2447232.0     0.147940           1.0          4  \n",
       "2020-10-23 13:00:00  2571386.0     0.044451           1.0          4  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_dfs['AAPL'].iloc[:15, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get train, valid, test splits for each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs = {}\n",
    "valid_dfs = {}\n",
    "test_dfs = {}\n",
    "\n",
    "split_dfs = {}\n",
    "\n",
    "for name in stock_dfs.keys():\n",
    "\n",
    "    # get stock DataFrame\n",
    "    df = stock_dfs[name]\n",
    "\n",
    "    train = df.loc[:'2022-02-01']\n",
    "    valid = df.loc['2022-02-02':'2022-07-01']\n",
    "    test = df.loc['2022-07-01':]\n",
    "\n",
    "    train_dfs.update({name : train})\n",
    "    valid_dfs.update({name : valid})\n",
    "    test_dfs.update({name : test})\n",
    "    \n",
    "    split_dfs.update({name : [train, valid, test]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data Generators\n",
    "- One for baseline model\n",
    "- One for simple non-sequential models (this will use window normalization)\n",
    "- One for sequential models (This will use window normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to make a Data Generator that that can account for the time spans that we are interested in. We might be able to use specific timestamps to define the windows, i.e. 09:30-13:30\n",
    "\n",
    "We should strive for a general method of doing this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift, dfs,\n",
    "                batch_size=32, seed=42, window_norm=True,\n",
    "                sample_weights=True, \n",
    "                remove_columns=[],\n",
    "                label_columns=None,\n",
    "                remove_nonsequential=False):\n",
    "        # Store the raw data.\n",
    "        self.train_df = dfs[0]\n",
    "        self.valid_df = dfs[1]\n",
    "        self.test_df = dfs[2]\n",
    "      \n",
    "        # self.position_encode = position_encode\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "        self.window_norm = window_norm\n",
    "        self.sample_weights = sample_weights\n",
    "        self.remove_columns = remove_columns\n",
    "        self.label_columns = label_columns\n",
    "        self.remove_nonsequential = remove_nonsequential # removes non-sequential windows\n",
    "\n",
    "        # standardize training features if window norm not selected\n",
    "        if not self.window_norm:\n",
    "            self.standardize()\n",
    "\n",
    "        # Work out the label column indices.\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in\n",
    "                                        enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in\n",
    "                                enumerate(self.train_df.columns)} \n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width # sequence length\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "      return '\\n'.join([\n",
    "          f'Total window size: {self.total_window_size}',\n",
    "          f'Input indices: {self.input_indices}',\n",
    "          f'Label indices: {self.label_indices}',\n",
    "          f'Label column name(s): {self.label_columns}'])\n",
    "\n",
    "    def standardize(self):\n",
    "        train_mean = self.train_df.mean()\n",
    "        train_std = self.train_df.std()\n",
    "\n",
    "        # ensure that target column is not standardized\n",
    "        for col in set(self.label_columns + self.remove_columns):\n",
    "            train_mean[col] = 0\n",
    "            train_std[col] = 1\n",
    "\n",
    "        self.train_df = (self.train_df - train_mean) / train_std\n",
    "        self.valid_df = (self.valid_df - train_mean) / train_std\n",
    "        self.test_df = (self.test_df - train_mean) / train_std\n",
    "\n",
    "\n",
    "    def split_window(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1)\n",
    "\n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        if self.remove_nonsequential:\n",
    "            inputs, labels = self.remove_nonsequential_windows(inputs, labels)\n",
    "\n",
    "        # remove desired columns from input features \n",
    "        if len(self.remove_columns) > 0:\n",
    "            inputs = tf.stack(\n",
    "                [inputs[:, :, self.column_indices[name]] for name in self.column_indices.keys() \n",
    "                                if name not in self.remove_columns],\n",
    "                axis=-1)\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "\n",
    "    def standardize_window(self, inputs, labels):\n",
    "        ''' Standardizes each window to mean - 0 and std - 1'''\n",
    "        mean = tf.math.reduce_mean(inputs, axis=1)\n",
    "        std = tf.math.reduce_std(inputs, axis=1)\n",
    "        \n",
    "        mean = tf.repeat(tf.expand_dims(mean, axis=1), \n",
    "                         self.total_window_size, axis=1)\n",
    "        std = tf.repeat(tf.expand_dims(std, axis=1), \n",
    "                        self.total_window_size, axis=1)\n",
    "\n",
    "        inputs = tf.math.subtract(inputs, mean)\n",
    "        inputs = tf.math.divide(inputs, std)\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "\n",
    "    def get_sample_weights(self, inputs, labels):\n",
    "        ''' Obtains smaple weights for any number of classes.\n",
    "            NOTE: sample_weights pertain a weighting to each label\n",
    "            '''\n",
    "        # get initial sample weights\n",
    "        sample_weights = tf.ones_like(labels, dtype=tf.float64)\n",
    "        \n",
    "        # get classes and counts for each one\n",
    "        class_counts = np.bincount(self.train_df.price_change)\n",
    "        total = class_counts.sum()\n",
    "        n_classes = len(class_counts)\n",
    "\n",
    "        for idx, count in enumerate(class_counts):\n",
    "            # compute weight\n",
    "            weight = total / (n_classes*count)\n",
    "\n",
    "            # update weight value \n",
    "            sample_weights = tf.where(tf.equal(labels, float(idx)), \n",
    "                                      weight, \n",
    "                                      sample_weights)\n",
    "        \n",
    "        return inputs, labels, sample_weights\n",
    "\n",
    "\n",
    "    def remove_sequence(self, inputs, labels, sample_weights=None):\n",
    "        # remove sequence from inputs so simple models can be trained (i.e. Linear Models)\n",
    "        inputs = tf.expand_dims(inputs[:, 0, :], axis=1)\n",
    "\n",
    "        if tf.is_tensor(sample_weights):\n",
    "            return inputs, labels, sample_weights\n",
    "        else:\n",
    "            return inputs, labels\n",
    "\n",
    "\n",
    "    def remove_nonsequential_windows(self, inputs, labels, sample_weights=None):\n",
    "        # ASSUMES that the dayofweek is the final features\n",
    "        # get locations of consistent dayofweeks in each batch\n",
    "        dayofweek_repeats = tf.repeat(tf.expand_dims(inputs[:, 0, -1], axis=1), \n",
    "                                      self.input_width, axis=1)\n",
    "        valid_locs = tf.reduce_all(inputs[:, :, -1] == dayofweek_repeats, axis=1)\n",
    "\n",
    "        inputs = inputs[valid_locs]\n",
    "        labels = labels[valid_locs]\n",
    "\n",
    "        if tf.is_tensor(sample_weights):\n",
    "            return inputs, labels, sample_weights\n",
    "        else:\n",
    "            return inputs, labels\n",
    "            \n",
    "    \n",
    "    def get_position_encoding(self, n=10000):\n",
    "        d = self.train_df.shape[1] # assume all features are used\n",
    "        pos_encode = np.zeros((self.input_width, d))\n",
    "        for k in range(self.input_width):\n",
    "            for i in np.arange(int(d/2)):\n",
    "                denominator = np.power(n, 2*i/d)\n",
    "                pos_encode[k, 2*i] = np.sin(k/denominator)\n",
    "                pos_encode[k, 2*i+1] = np.cos(k/denominator)\n",
    "        return pos_encode\n",
    "\n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "                data=data,\n",
    "                targets=None,\n",
    "                sequence_length=self.total_window_size,\n",
    "                sequence_stride=1,\n",
    "                shuffle=False,\n",
    "                seed=self.seed,\n",
    "                batch_size=self.batch_size)\n",
    "\n",
    "        # get split window\n",
    "        ds = ds.map(self.split_window)\n",
    "\n",
    "        if self.window_norm:\n",
    "            ds = ds.map(self.standardize_window)\n",
    "\n",
    "        if self.sample_weights:\n",
    "            ds = ds.map(self.get_sample_weights)\n",
    "\n",
    "        return ds\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "\n",
    "    @property\n",
    "    def valid(self):\n",
    "        return self.make_dataset(self.valid_df)\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df)\n",
    "\n",
    "    @property\n",
    "    def example(self):\n",
    "        \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "        result = getattr(self, '_example', None)\n",
    "        if result is None:\n",
    "            # No example batch was found, so get one from the `.train` dataset\n",
    "            result = next(iter(self.train))\n",
    "            # And cache it for next time\n",
    "            self._example = result\n",
    "        # return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use shift=0 since the targets are aligned with each feature row\n",
    "aapl_gen = WindowGenerator(\n",
    "                input_width=24, label_width=1, shift=0, \n",
    "                window_norm=False,\n",
    "                dfs=split_dfs['AAPL'],\n",
    "                remove_columns=['price_change', 'price_trend', 'dayofweek'],\n",
    "                batch_size=32, \n",
    "                remove_nonsequential=True,\n",
    "                label_columns=['price_change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape (batch, time, features): (8, 24, 5)\n",
      "Labels shape (batch, time, features): (8, 1, 1)\n",
      "Inputs shape (batch, time, features): (4, 24, 5)\n",
      "Labels shape (batch, time, features): (4, 1, 1)\n",
      "Inputs shape (batch, time, features): (4, 24, 5)\n",
      "Labels shape (batch, time, features): (4, 1, 1)\n",
      "Inputs shape (batch, time, features): (4, 24, 5)\n",
      "Labels shape (batch, time, features): (4, 1, 1)\n",
      "Inputs shape (batch, time, features): (4, 24, 5)\n",
      "Labels shape (batch, time, features): (4, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels, sample_weights in aapl_gen.train.take(5):\n",
    "    print(f'Inputs shape (batch, time, features): {inputs.shape}')\n",
    "    print(f'Labels shape (batch, time, features): {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_gens = []\n",
    "single_step_gens = []\n",
    "window_generators = []\n",
    "\n",
    "for name in split_dfs.keys():\n",
    "    base_gen = WindowGenerator(\n",
    "        input_width=1, label_width=1, shift=0,\n",
    "        dfs=split_dfs[name],\n",
    "        batch_size=32, \n",
    "        label_columns=['price_change'])\n",
    "\n",
    "    single_gen = WindowGenerator(\n",
    "                input_width=1, label_width=1, shift=0, \n",
    "                window_norm=False,\n",
    "                dfs=split_dfs[name],\n",
    "                remove_columns=['price_change', 'price_trend', 'dayofweek'],\n",
    "                batch_size=32, \n",
    "                remove_nonsequential=True,\n",
    "                label_columns=['price_change'])\n",
    "\n",
    "    data_gen = WindowGenerator(\n",
    "                input_width=24, label_width=1, shift=0, \n",
    "                window_norm=True,\n",
    "                dfs=split_dfs[name],\n",
    "                remove_columns=['price_change', 'price_trend', 'dayofweek'],\n",
    "                batch_size=32, \n",
    "                remove_nonsequential=True,\n",
    "                label_columns=['price_change'])\n",
    "    \n",
    "    base_gens.append(base_gen)\n",
    "    single_step_gens.append(single_gen)\n",
    "    window_generators.append(data_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(tf.keras.Model):\n",
    "    def __init__(self, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None:\n",
    "            return inputs\n",
    "        result = inputs[:, :, self.label_index]\n",
    "        return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_performance = {}\n",
    "val_performance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.2350 - weighted_accuracy: 0.3333\n",
      "88/88 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.3376 - weighted_accuracy: 0.4098\n",
      "268/268 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.1422 - weighted_accuracy: 0.3333\n",
      "88/88 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.2791 - weighted_accuracy: 0.4585\n",
      "270/270 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.1707 - weighted_accuracy: 0.3333\n",
      "88/88 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.3117 - weighted_accuracy: 0.4457\n",
      "270/270 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.2373 - weighted_accuracy: 0.3333\n",
      "88/88 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.3405 - weighted_accuracy: 0.4170\n"
     ]
    }
   ],
   "source": [
    "train_metrics = []\n",
    "val_metrics = []\n",
    "for data_gen in base_gens:\n",
    "    baseline = Baseline(label_index=data_gen.column_indices['price_change'])\n",
    "\n",
    "    baseline.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                     metrics=['accuracy'],\n",
    "                     weighted_metrics=['accuracy'])\n",
    "\n",
    "    train_metrics.append(baseline.evaluate(data_gen.train))\n",
    "    val_metrics.append(baseline.evaluate(data_gen.valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_performance['Baseline'] = train_metrics\n",
    "val_performance['Baseline'] = val_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Linear model\n",
    "Entire dataset is standardized here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = tf.keras.Sequential([\n",
    "    layers.Dense(units=3, activation='softmax')\n",
    "])\n",
    "\n",
    "linear.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "    weighted_metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAIN EPOCH: 1\n",
      "\n",
      "270/270 [==============================] - 3s 6ms/step - loss: 1.1069 - sparse_categorical_accuracy: 0.4409 - weighted_sparse_categorical_accuracy: 0.3921 - val_loss: 1.2942 - val_sparse_categorical_accuracy: 0.3497 - val_weighted_sparse_categorical_accuracy: 0.3688\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 1.1152 - sparse_categorical_accuracy: 0.4998 - weighted_sparse_categorical_accuracy: 0.3969\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.2942 - sparse_categorical_accuracy: 0.3497 - weighted_sparse_categorical_accuracy: 0.3688\n",
      "\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1.0846 - sparse_categorical_accuracy: 0.5099 - weighted_sparse_categorical_accuracy: 0.3913 - val_loss: 1.5315 - val_sparse_categorical_accuracy: 0.3569 - val_weighted_sparse_categorical_accuracy: 0.3782\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1.1156 - sparse_categorical_accuracy: 0.4287 - weighted_sparse_categorical_accuracy: 0.3810\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.5315 - sparse_categorical_accuracy: 0.3569 - weighted_sparse_categorical_accuracy: 0.3782\n",
      "\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 1.0766 - sparse_categorical_accuracy: 0.4562 - weighted_sparse_categorical_accuracy: 0.3928 - val_loss: 1.6161 - val_sparse_categorical_accuracy: 0.3851 - val_weighted_sparse_categorical_accuracy: 0.2916\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 1.1044 - sparse_categorical_accuracy: 0.5908 - weighted_sparse_categorical_accuracy: 0.4154\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.6161 - sparse_categorical_accuracy: 0.3851 - weighted_sparse_categorical_accuracy: 0.2916\n",
      "\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 1.0527 - sparse_categorical_accuracy: 0.4946 - weighted_sparse_categorical_accuracy: 0.4295 - val_loss: 1.2610 - val_sparse_categorical_accuracy: 0.3878 - val_weighted_sparse_categorical_accuracy: 0.3616\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 1.0746 - sparse_categorical_accuracy: 0.5444 - weighted_sparse_categorical_accuracy: 0.4439\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.2610 - sparse_categorical_accuracy: 0.3878 - weighted_sparse_categorical_accuracy: 0.3616\n",
      "\n",
      "MAIN EPOCH: 2\n",
      "\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 1.0924 - sparse_categorical_accuracy: 0.4779 - weighted_sparse_categorical_accuracy: 0.4048 - val_loss: 1.2973 - val_sparse_categorical_accuracy: 0.3515 - val_weighted_sparse_categorical_accuracy: 0.3700\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 1.1131 - sparse_categorical_accuracy: 0.5031 - weighted_sparse_categorical_accuracy: 0.3985\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.2973 - sparse_categorical_accuracy: 0.3515 - weighted_sparse_categorical_accuracy: 0.3700\n",
      "\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1.0832 - sparse_categorical_accuracy: 0.5127 - weighted_sparse_categorical_accuracy: 0.3925 - val_loss: 1.5280 - val_sparse_categorical_accuracy: 0.3587 - val_weighted_sparse_categorical_accuracy: 0.3820\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1.1137 - sparse_categorical_accuracy: 0.4260 - weighted_sparse_categorical_accuracy: 0.3808\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.5280 - sparse_categorical_accuracy: 0.3587 - weighted_sparse_categorical_accuracy: 0.3820\n",
      "\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 1.0745 - sparse_categorical_accuracy: 0.4603 - weighted_sparse_categorical_accuracy: 0.4024 - val_loss: 1.6139 - val_sparse_categorical_accuracy: 0.3876 - val_weighted_sparse_categorical_accuracy: 0.2952\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 1.1032 - sparse_categorical_accuracy: 0.5913 - weighted_sparse_categorical_accuracy: 0.4160\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.6139 - sparse_categorical_accuracy: 0.3876 - weighted_sparse_categorical_accuracy: 0.2952\n",
      "\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 1.0516 - sparse_categorical_accuracy: 0.4977 - weighted_sparse_categorical_accuracy: 0.4337 - val_loss: 1.2590 - val_sparse_categorical_accuracy: 0.3932 - val_weighted_sparse_categorical_accuracy: 0.3683\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 1.0734 - sparse_categorical_accuracy: 0.5453 - weighted_sparse_categorical_accuracy: 0.4455\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.2590 - sparse_categorical_accuracy: 0.3932 - weighted_sparse_categorical_accuracy: 0.3683\n"
     ]
    }
   ],
   "source": [
    "train_metrics = []\n",
    "val_metrics = []\n",
    "\n",
    "EPOCHS = 2\n",
    "for e in range(1, EPOCHS+1):\n",
    "    print(f'\\nMAIN EPOCH: {e}')\n",
    "    for data_gen in single_step_gens:\n",
    "        print()\n",
    "        \n",
    "        history = linear.fit(\n",
    "                            data_gen.train, epochs=1,\n",
    "                            validation_data=data_gen.valid)\n",
    "\n",
    "        train_metrics.append(linear.evaluate(data_gen.train))\n",
    "        val_metrics.append(linear.evaluate(data_gen.valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_performance['Linear'] = train_metrics\n",
    "val_performance['Linear'] = val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = TransformerModel(\n",
    "            n_heads=2,\n",
    "            d_model=512,\n",
    "            ff_dim=256,\n",
    "            num_transformer_blocks=2,\n",
    "            mlp_units=[256],\n",
    "            n_outputs=3,\n",
    "            dropout=0.1,\n",
    "            mlp_dropout=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model on each dataset once per epoch\n",
    "\n",
    "TODO - add new functions to make this easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARN_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model.compile(\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=LEARN_RATE),\n",
    "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "                  weighted_metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAIN EPOCH: 1\n",
      "\n",
      "270/270 [==============================] - 14s 25ms/step - loss: 1.0109 - sparse_categorical_accuracy: 0.5739 - weighted_sparse_categorical_accuracy: 0.3705 - val_loss: 1.3130 - val_sparse_categorical_accuracy: 0.3365 - val_weighted_sparse_categorical_accuracy: 0.1809\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 1.0048 - sparse_categorical_accuracy: 0.5708 - weighted_sparse_categorical_accuracy: 0.3698\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.3130 - sparse_categorical_accuracy: 0.3365 - weighted_sparse_categorical_accuracy: 0.1809\n",
      "\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 0.9643 - sparse_categorical_accuracy: 0.7246 - weighted_sparse_categorical_accuracy: 0.3541 - val_loss: 1.6613 - val_sparse_categorical_accuracy: 0.4596 - val_weighted_sparse_categorical_accuracy: 0.1481\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 0.9607 - sparse_categorical_accuracy: 0.7270 - weighted_sparse_categorical_accuracy: 0.3521\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 1.6613 - sparse_categorical_accuracy: 0.4596 - weighted_sparse_categorical_accuracy: 0.1481\n",
      "\n",
      "269/269 [==============================] - 6s 21ms/step - loss: 0.9373 - sparse_categorical_accuracy: 0.7050 - weighted_sparse_categorical_accuracy: 0.3823 - val_loss: 1.5039 - val_sparse_categorical_accuracy: 0.4410 - val_weighted_sparse_categorical_accuracy: 0.1686\n",
      "269/269 [==============================] - 2s 7ms/step - loss: 0.9290 - sparse_categorical_accuracy: 0.7082 - weighted_sparse_categorical_accuracy: 0.3840\n",
      "87/87 [==============================] - 1s 8ms/step - loss: 1.5039 - sparse_categorical_accuracy: 0.4410 - weighted_sparse_categorical_accuracy: 0.1686\n",
      "\n",
      "270/270 [==============================] - 6s 21ms/step - loss: 0.9742 - sparse_categorical_accuracy: 0.5967 - weighted_sparse_categorical_accuracy: 0.3922 - val_loss: 1.1652 - val_sparse_categorical_accuracy: 0.4712 - val_weighted_sparse_categorical_accuracy: 0.2793\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.9642 - sparse_categorical_accuracy: 0.5975 - weighted_sparse_categorical_accuracy: 0.3927\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.1652 - sparse_categorical_accuracy: 0.4712 - weighted_sparse_categorical_accuracy: 0.2793\n",
      "\n",
      "MAIN EPOCH: 2\n",
      "\n",
      "270/270 [==============================] - 6s 21ms/step - loss: 0.9913 - sparse_categorical_accuracy: 0.5684 - weighted_sparse_categorical_accuracy: 0.3747 - val_loss: 1.3364 - val_sparse_categorical_accuracy: 0.3341 - val_weighted_sparse_categorical_accuracy: 0.1912\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.9822 - sparse_categorical_accuracy: 0.5715 - weighted_sparse_categorical_accuracy: 0.3884\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.3364 - sparse_categorical_accuracy: 0.3341 - weighted_sparse_categorical_accuracy: 0.1912\n",
      "\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 0.9608 - sparse_categorical_accuracy: 0.7163 - weighted_sparse_categorical_accuracy: 0.3517 - val_loss: 1.6701 - val_sparse_categorical_accuracy: 0.4596 - val_weighted_sparse_categorical_accuracy: 0.1514\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 0.9459 - sparse_categorical_accuracy: 0.7237 - weighted_sparse_categorical_accuracy: 0.3505\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 1.6701 - sparse_categorical_accuracy: 0.4596 - weighted_sparse_categorical_accuracy: 0.1514\n",
      "\n",
      "269/269 [==============================] - 6s 21ms/step - loss: 0.9200 - sparse_categorical_accuracy: 0.6995 - weighted_sparse_categorical_accuracy: 0.3867 - val_loss: 1.5172 - val_sparse_categorical_accuracy: 0.4410 - val_weighted_sparse_categorical_accuracy: 0.1686\n",
      "269/269 [==============================] - 2s 7ms/step - loss: 0.9096 - sparse_categorical_accuracy: 0.7050 - weighted_sparse_categorical_accuracy: 0.3823\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 1.5172 - sparse_categorical_accuracy: 0.4410 - weighted_sparse_categorical_accuracy: 0.1686\n",
      "\n",
      "270/270 [==============================] - 6s 21ms/step - loss: 0.9526 - sparse_categorical_accuracy: 0.5983 - weighted_sparse_categorical_accuracy: 0.3979 - val_loss: 1.1714 - val_sparse_categorical_accuracy: 0.4663 - val_weighted_sparse_categorical_accuracy: 0.2943\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.9453 - sparse_categorical_accuracy: 0.6014 - weighted_sparse_categorical_accuracy: 0.4141\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.1714 - sparse_categorical_accuracy: 0.4663 - weighted_sparse_categorical_accuracy: 0.2943\n"
     ]
    }
   ],
   "source": [
    "train_metrics = []\n",
    "val_metrics = []\n",
    "\n",
    "EPOCHS = 2\n",
    "for e in range(1, EPOCHS+1):\n",
    "    print(f'\\nMAIN EPOCH: {e}')\n",
    "    for window in window_generators:\n",
    "        print()\n",
    "        \n",
    "        history = transformer_model.fit(\n",
    "                            window.train, epochs=1,\n",
    "                            validation_data=window.valid)\n",
    "\n",
    "        train_metrics.append(transformer_model.evaluate(window.train))\n",
    "        val_metrics.append(transformer_model.evaluate(window.valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_performance['Transformer'] = train_metrics\n",
    "val_performance['Transformer'] = val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Baseline': [[nan, 0.23500116169452667, 0.33333343267440796],\n",
       "  [nan, 0.1422237753868103, 0.3333333730697632],\n",
       "  [nan, 0.17068366706371307, 0.3333333432674408],\n",
       "  [nan, 0.23731757700443268, 0.33333349227905273]],\n",
       " 'Linear': [[1.1152030229568481, 0.49976834654808044, 0.3968563973903656],\n",
       "  [1.1156154870986938, 0.4286547601222992, 0.3810034394264221],\n",
       "  [1.1044002771377563, 0.5908458828926086, 0.4153568744659424],\n",
       "  [1.0745733976364136, 0.5443595051765442, 0.44394993782043457],\n",
       "  [1.1131197214126587, 0.5031271576881409, 0.3985099494457245],\n",
       "  [1.1136819124221802, 0.42597129940986633, 0.380776047706604],\n",
       "  [1.1032155752182007, 0.5913093686103821, 0.415955513715744],\n",
       "  [1.0734285116195679, 0.5452860593795776, 0.4454851448535919]],\n",
       " 'Transformer': [[1.004834532737732, 0.5707547068595886, 0.36977294087409973],\n",
       "  [0.9606955647468567, 0.7270471453666687, 0.35207444429397583],\n",
       "  [0.9290105104446411, 0.7082018852233887, 0.3839963376522064],\n",
       "  [0.964201033115387, 0.597484290599823, 0.39271971583366394],\n",
       "  [0.982217013835907, 0.571540892124176, 0.38838842511177063],\n",
       "  [0.9459103345870972, 0.7237386107444763, 0.3504723310470581],\n",
       "  [0.9095633029937744, 0.7050473093986511, 0.3822858929634094],\n",
       "  [0.9453175067901611, 0.6014150977134705, 0.4140772521495819]]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Baseline': [[nan, 0.33760684728622437, 0.40984562039375305],\n",
       "  [nan, 0.27905309200286865, 0.4584830701351166],\n",
       "  [nan, 0.31172069907188416, 0.44568681716918945],\n",
       "  [nan, 0.3404558300971985, 0.41701656579971313]],\n",
       " 'Linear': [[1.2942137718200684, 0.34971511363983154, 0.3688000440597534],\n",
       "  [1.5314561128616333, 0.3568866550922394, 0.378169447183609],\n",
       "  [1.616060495376587, 0.3851086497306824, 0.2915721535682678],\n",
       "  [1.2609810829162598, 0.3878205120563507, 0.3616245985031128],\n",
       "  [1.29726243019104, 0.3514957129955292, 0.370029479265213],\n",
       "  [1.5280370712280273, 0.3586800694465637, 0.3819565176963806],\n",
       "  [1.6138532161712646, 0.38760241866111755, 0.2951911389827728],\n",
       "  [1.2590135335922241, 0.39316239953041077, 0.36829179525375366]],\n",
       " 'Transformer': [[1.3129642009735107, 0.3365384638309479, 0.1809397041797638],\n",
       "  [1.6613001823425293, 0.4595959484577179, 0.14814011752605438],\n",
       "  [1.5038597583770752, 0.44096386432647705, 0.1685536801815033],\n",
       "  [1.165165662765503, 0.4711538553237915, 0.27929094433784485],\n",
       "  [1.336381435394287, 0.33413460850715637, 0.19119563698768616],\n",
       "  [1.6700749397277832, 0.4595959484577179, 0.1513846069574356],\n",
       "  [1.5172427892684937, 0.44096386432647705, 0.1685536801815033],\n",
       "  [1.1714304685592651, 0.4663461446762085, 0.2942929267883301]]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model for future usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " positional_embedding (Posit  multiple                 3584      \n",
      " ionalEmbedding)                                                 \n",
      "                                                                 \n",
      " transformer_encoder (Transf  multiple                 2362624   \n",
      " ormerEncoder)                                                   \n",
      "                                                                 \n",
      " transformer_encoder_1 (Tran  multiple                 2362624   \n",
      " sformerEncoder)                                                 \n",
      "                                                                 \n",
      " global_average_pooling1d (G  multiple                 0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  8448      \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,738,051\n",
      "Trainable params: 4,738,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_2_layer_call_fn, dense_2_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn, multi_head_attention_layer_call_and_return_conditional_losses, dropout_2_layer_call_fn while saving (showing 5 of 38). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/basic_transformer_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/basic_transformer_checkpoint\\assets\n",
      "WARNING:absl:<tensorflow_addons.layers.multihead_attention.MultiHeadAttention object at 0x0000026E07D79F10> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'tensorflow_addons.layers.multihead_attention.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tensorflow_addons.layers.multihead_attention.MultiHeadAttention object at 0x0000026E09294F70> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'tensorflow_addons.layers.multihead_attention.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "transformer_model.save('models/basic_transformer_checkpoint', include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.layers import multihead_attention\n",
    "\n",
    "custom_objects={\n",
    "    'MultiHeadAttention' : multihead_attention.MultiHeadAttention,\n",
    "    'TransformerModel' : TransformerModel}\n",
    "\n",
    "reconstructed_model = keras.models.load_model('models/basic_transformer_checkpoint',\n",
    "                                              custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "638/638 [==============================] - 40s 59ms/step - loss: 0.8315 - sparse_categorical_accuracy: 0.6993 - weighted_sparse_categorical_accuracy: 0.3950 - val_loss: 0.8886 - val_sparse_categorical_accuracy: 0.7210 - val_weighted_sparse_categorical_accuracy: 0.6870\n",
      "Epoch 2/2\n",
      "174/638 [=======>......................] - ETA: 25s - loss: 0.6626 - sparse_categorical_accuracy: 0.7633 - weighted_sparse_categorical_accuracy: 0.6517"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23300\\1409055518.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdata_gen\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwindow_generators\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     compile_and_fit(reconstructed_model, data_gen, lr=1e-4,\n\u001b[0m\u001b[0;32m      6\u001b[0m                     patience=2, max_epochs=2)\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23300\\611053135.py\u001b[0m in \u001b[0;36mcompile_and_fit\u001b[1;34m(model, window, lr, max_epochs, patience)\u001b[0m\n\u001b[0;32m      9\u001b[0m                   weighted_metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     history = model.fit(window.train, epochs=max_epochs,\n\u001b[0m\u001b[0;32m     12\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                         callbacks=[early_stopping])\n",
      "\u001b[1;32mc:\\Users\\itber\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\itber\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1412\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1413\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1414\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1415\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1416\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\itber\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \"\"\"\n\u001b[0;32m    437\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\itber\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m       raise ValueError(\n",
      "\u001b[1;32mc:\\Users\\itber\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\itber\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\itber\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1034\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\itber\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1104\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1106\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\itber\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    605\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\itber\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 916\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    917\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\itber\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 916\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    917\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\itber\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m       \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m     \u001b[1;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\itber\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1157\u001b[0m     \"\"\"\n\u001b[0;32m   1158\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1159\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1160\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\itber\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1125\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1126\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_metrics = []\n",
    "val_metrics = []\n",
    "for data_gen in window_generators:\n",
    "\n",
    "    compile_and_fit(reconstructed_model, data_gen, lr=1e-4,\n",
    "                    patience=2, max_epochs=2)\n",
    "\n",
    "    train_metrics.append(transformer_model.evaluate(data_gen.train))\n",
    "    val_metrics.append(transformer_model.evaluate(data_gen.valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b2da39daaaff30a84159e8452ba91acfc0bbd521fb66c6aa9941f847b87bd81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
