{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Models\n",
    "\n",
    "In this notebook, we will explore some Toy Models to perform classification of price movement on a few data sets of stock data. We will preprocess the stock data to contain the Times in the form of sines and cosines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from window_generator import WindowGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for python scripts use: \"os.path.dirname(__file__)\" instead of \"os.path.abspath('')\"\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.abspath(''), os.path.pardir)))\n",
    "\n",
    "from data_clean import get_trading_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensure that GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.7421812, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "true = [0.0, 1.0]\n",
    "pred = [[0.1,0.9],[0.0,1.0]]\n",
    "\n",
    "tt = tf.convert_to_tensor(true)\n",
    "tp = tf.convert_to_tensor(pred)\n",
    "\n",
    "l = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "ret = l(tt,tp)\n",
    "\n",
    "print(ret)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'..\\data\\raw\\AAPL_15min.csv'\n",
    "df = pd.read_csv(data_path, index_col=0, \n",
    "                 parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "# df = get_trading_times(df)\n",
    "df = df.dropna()\n",
    "\n",
    "# add days, hours, and minutes to the dataset\n",
    "dayofweek = df.index.dayofweek\n",
    "hour = df.index.hour\n",
    "minute = df.index.minute\n",
    "\n",
    "# encode the days, hours, and minutes with sin and cos functions\n",
    "eps = 1e-4 # ensure that encodings don't have NaNs\n",
    "# df['sin_day'] = np.sin(2*np.pi/(dayofweek + eps))\n",
    "# df['cos_day'] = np.cos(2*np.pi/(dayofweek + eps))\n",
    "# df['sin_hour'] = np.sin(2*np.pi/(hour + eps))\n",
    "# df['cos_hour'] = np.cos(2*np.pi/(hour + eps))\n",
    "# df['sin_minute'] = np.sin(2*np.pi/(minute + eps))\n",
    "# df['cos_minute'] = np.cos(2*np.pi/(minute + eps))\n",
    "\n",
    "\n",
    "days_in_week = 7\n",
    "hours_in_day = 24\n",
    "minutes_in_hour = 60\n",
    "\n",
    "df['sin_day'] = np.sin(2*np.pi*dayofweek/days_in_week)\n",
    "df['cos_day'] = np.cos(2*np.pi*dayofweek/days_in_week)\n",
    "df['sin_hour'] = np.sin(2*np.pi*hour/hours_in_day)\n",
    "df['cos_hour'] = np.cos(2*np.pi*hour/hours_in_day)\n",
    "df['sin_minute'] = np.sin(2*np.pi*minute/minutes_in_hour)\n",
    "df['cos_minute'] = np.cos(2*np.pi*minute/minutes_in_hour)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add target columns\n",
    "We will add a column for price change at each interval, this will be our regression target variable. We will also add another column that quantifys the magnitude of the price change, this will be out target variable for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itber\\AppData\\Local\\Temp\\ipykernel_9996\\2560370332.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['price_change'][df['price_diff'] < -thresh] = 0 # downward price movement\n",
      "C:\\Users\\itber\\AppData\\Local\\Temp\\ipykernel_9996\\2560370332.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['price_change'][df['price_diff'] > thresh] = 2 # upward prive movement\n"
     ]
    }
   ],
   "source": [
    "df['price_diff'] = df['close'].diff()\n",
    "\n",
    "thresh = 0.1 # dollars\n",
    "df['price_change'] = 1 # price stays the same\n",
    "df['price_change'][df['price_diff'] < -thresh] = 0 # downward price movement\n",
    "df['price_change'][df['price_diff'] > thresh] = 2 # upward prive movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>sin_day</th>\n",
       "      <th>cos_day</th>\n",
       "      <th>sin_hour</th>\n",
       "      <th>cos_hour</th>\n",
       "      <th>sin_minute</th>\n",
       "      <th>cos_minute</th>\n",
       "      <th>price_diff</th>\n",
       "      <th>price_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-01 04:30:00</th>\n",
       "      <td>115.634512</td>\n",
       "      <td>115.792604</td>\n",
       "      <td>115.407254</td>\n",
       "      <td>115.407254</td>\n",
       "      <td>13550.0</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.665539e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-0.207496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 04:45:00</th>\n",
       "      <td>115.367731</td>\n",
       "      <td>115.367731</td>\n",
       "      <td>115.120712</td>\n",
       "      <td>115.308447</td>\n",
       "      <td>12857.0</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-0.098808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 05:00:00</th>\n",
       "      <td>115.308447</td>\n",
       "      <td>115.397374</td>\n",
       "      <td>115.298566</td>\n",
       "      <td>115.318327</td>\n",
       "      <td>10079.0</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 05:15:00</th>\n",
       "      <td>115.417135</td>\n",
       "      <td>115.604869</td>\n",
       "      <td>115.377612</td>\n",
       "      <td>115.604869</td>\n",
       "      <td>3534.0</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.832769e-16</td>\n",
       "      <td>0.286542</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 05:30:00</th>\n",
       "      <td>115.604869</td>\n",
       "      <td>115.703677</td>\n",
       "      <td>115.555466</td>\n",
       "      <td>115.703677</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>5.665539e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.098808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           open        high         low       close   volume  \\\n",
       "time                                                                           \n",
       "2020-10-01 04:30:00  115.634512  115.792604  115.407254  115.407254  13550.0   \n",
       "2020-10-01 04:45:00  115.367731  115.367731  115.120712  115.308447  12857.0   \n",
       "2020-10-01 05:00:00  115.308447  115.397374  115.298566  115.318327  10079.0   \n",
       "2020-10-01 05:15:00  115.417135  115.604869  115.377612  115.604869   3534.0   \n",
       "2020-10-01 05:30:00  115.604869  115.703677  115.555466  115.703677   7688.0   \n",
       "\n",
       "                      sin_day   cos_day  sin_hour  cos_hour    sin_minute  \\\n",
       "time                                                                        \n",
       "2020-10-01 04:30:00  0.433884 -0.900969  0.866025  0.500000  5.665539e-16   \n",
       "2020-10-01 04:45:00  0.433884 -0.900969  0.866025  0.500000 -1.000000e+00   \n",
       "2020-10-01 05:00:00  0.433884 -0.900969  0.965926  0.258819  0.000000e+00   \n",
       "2020-10-01 05:15:00  0.433884 -0.900969  0.965926  0.258819  1.000000e+00   \n",
       "2020-10-01 05:30:00  0.433884 -0.900969  0.965926  0.258819  5.665539e-16   \n",
       "\n",
       "                       cos_minute  price_diff  price_change  \n",
       "time                                                         \n",
       "2020-10-01 04:30:00 -1.000000e+00   -0.207496             0  \n",
       "2020-10-01 04:45:00 -1.836970e-16   -0.098808             1  \n",
       "2020-10-01 05:00:00  1.000000e+00    0.009881             1  \n",
       "2020-10-01 05:15:00  2.832769e-16    0.286542             2  \n",
       "2020-10-01 05:30:00 -1.000000e+00    0.098808             1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Standardized train, valid, and test sets\n",
    "\n",
    "Split into train, valid, and test sets. And then standardize with training mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16112, 13)\n",
      "(9243, 13)\n",
      "(6267, 13)\n"
     ]
    }
   ],
   "source": [
    "train_df = df.loc['2020-10-01':'2021-10-01']\n",
    "valid_df = df.loc['2021-10-02':'2022-05-01']\n",
    "test_df = df.loc['2022-05-02':]\n",
    "\n",
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "# ensure that target column is not standardized\n",
    "train_mean.price_change = 0\n",
    "train_std.price_change = 1\n",
    "\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "valid_df = (valid_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std\n",
    "\n",
    "\n",
    "print(train_df.shape)\n",
    "print(valid_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data Generator for each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = WindowGenerator(\n",
    "                input_width=12, label_width=1, shift=1, \n",
    "                train_df=train_df, valid_df=valid_df, test_df=test_df,\n",
    "                label_columns=['price_change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape (batch, time, features): (32, 12, 13)\n",
      "Targets shape (batch, time, features): (32, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in data_gen.train.take(1):\n",
    "    print(f'Inputs shape (batch, time, features): {inputs.shape}')\n",
    "    print(f'Targets shape (batch, time, features): {targets.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Start Training Models**\n",
    "\n",
    "First we will need a baseline model to compare our results to. The most simple baseline model will just predict the next value by using the previous value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(tf.keras.Model):\n",
    "    def __init__(self, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None:\n",
    "            return inputs\n",
    "        result = inputs[:, :, self.label_index]\n",
    "        return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_step_window = WindowGenerator(\n",
    "        input_width=1, label_width=1, shift=1,\n",
    "        train_df=train_df, valid_df=valid_df, test_df=test_df,\n",
    "        label_columns=['price_change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.4091\n"
     ]
    }
   ],
   "source": [
    "baseline = Baseline(label_index=single_step_window.column_indices['price_change'])\n",
    "\n",
    "baseline.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "val_performance = {}\n",
    "performance = {}\n",
    "val_performance['Baseline'] = baseline.evaluate(single_step_window.valid)\n",
    "performance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's train some more in depth models\n",
    "\n",
    "First we will define a helper function to streamline this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit(model, window, lr=1e-4, max_epochs=100, patience=2):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                      patience=patience,\n",
    "                                                      mode='min')\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(window.train, epochs=max_epochs,\n",
    "                        validation_data=window.valid,\n",
    "                        callbacks=[early_stopping])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.Sequential([\n",
    "    layers.Dense(units=64, activation='relu'),\n",
    "    layers.Dense(units=64, activation='relu'),\n",
    "    layers.Dense(units=3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 1.0105 - accuracy: 0.5028 - val_loss: 1.2047 - val_accuracy: 0.4082\n",
      "Epoch 2/10\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.9750 - accuracy: 0.5239 - val_loss: 1.1565 - val_accuracy: 0.4203\n",
      "Epoch 3/10\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.9626 - accuracy: 0.5285 - val_loss: 1.1289 - val_accuracy: 0.4279\n",
      "Epoch 4/10\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.9568 - accuracy: 0.5320 - val_loss: 1.1099 - val_accuracy: 0.4325\n",
      "Epoch 5/10\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.9527 - accuracy: 0.5344 - val_loss: 1.0964 - val_accuracy: 0.4366\n",
      "Epoch 6/10\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.9494 - accuracy: 0.5355 - val_loss: 1.0852 - val_accuracy: 0.4425\n",
      "Epoch 7/10\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.9467 - accuracy: 0.5358 - val_loss: 1.0778 - val_accuracy: 0.4446\n",
      "Epoch 8/10\n",
      "504/504 [==============================] - 3s 7ms/step - loss: 0.9443 - accuracy: 0.5378 - val_loss: 1.0710 - val_accuracy: 0.4482\n",
      "Epoch 9/10\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.9422 - accuracy: 0.5387 - val_loss: 1.0664 - val_accuracy: 0.4484\n",
      "Epoch 10/10\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.9404 - accuracy: 0.5406 - val_loss: 1.0623 - val_accuracy: 0.4489\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 1.0623 - accuracy: 0.4489\n"
     ]
    }
   ],
   "source": [
    "history = compile_and_fit(dense, single_step_window, max_epochs=10)\n",
    "\n",
    "val_performance['Dense'] = dense.evaluate(single_step_window.valid)\n",
    "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 1, 13])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(single_step_window.train.take(1)))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 1, 3])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense(next(iter(single_step_window.train.take(1)))[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a dense NN model with a few time steps. We can use the Flatten() command to flatten out inputs as they are fed into the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_step_dense = tf.keras.Sequential([\n",
    "    # Shape: (time, features) => (time*features)\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units=64, activation='relu'),\n",
    "    layers.Dense(units=64, activation='relu'),\n",
    "    layers.Dense(units=3, activation='softmax'),\n",
    "    # Add back the time dimension.\n",
    "    # Shape: (outputs) => (1, outputs)\n",
    "    layers.Reshape([1, -1]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 1.0623 - accuracy: 0.4717 - val_loss: 1.1579 - val_accuracy: 0.4282\n",
      "Epoch 2/10\n",
      "504/504 [==============================] - 3s 5ms/step - loss: 0.9902 - accuracy: 0.5208 - val_loss: 1.1213 - val_accuracy: 0.4425\n",
      "Epoch 3/10\n",
      "504/504 [==============================] - 2s 5ms/step - loss: 0.9743 - accuracy: 0.5306 - val_loss: 1.1031 - val_accuracy: 0.4548\n",
      "Epoch 4/10\n",
      "504/504 [==============================] - 3s 5ms/step - loss: 0.9636 - accuracy: 0.5367 - val_loss: 1.0962 - val_accuracy: 0.4536\n",
      "Epoch 5/10\n",
      "504/504 [==============================] - 3s 5ms/step - loss: 0.9555 - accuracy: 0.5396 - val_loss: 1.0873 - val_accuracy: 0.4586\n",
      "Epoch 6/10\n",
      "504/504 [==============================] - 3s 5ms/step - loss: 0.9490 - accuracy: 0.5432 - val_loss: 1.0784 - val_accuracy: 0.4579\n",
      "Epoch 7/10\n",
      "504/504 [==============================] - 3s 5ms/step - loss: 0.9434 - accuracy: 0.5470 - val_loss: 1.0725 - val_accuracy: 0.4600\n",
      "Epoch 8/10\n",
      "504/504 [==============================] - 2s 5ms/step - loss: 0.9384 - accuracy: 0.5497 - val_loss: 1.0671 - val_accuracy: 0.4615\n",
      "Epoch 9/10\n",
      "504/504 [==============================] - 2s 5ms/step - loss: 0.9339 - accuracy: 0.5519 - val_loss: 1.0634 - val_accuracy: 0.4618\n",
      "Epoch 10/10\n",
      "504/504 [==============================] - 2s 5ms/step - loss: 0.9297 - accuracy: 0.5549 - val_loss: 1.0594 - val_accuracy: 0.4626\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 1.0594 - accuracy: 0.4626\n"
     ]
    }
   ],
   "source": [
    "history = compile_and_fit(multi_step_dense, data_gen, max_epochs=10)\n",
    "\n",
    "val_performance['Multi step dense'] = multi_step_dense.evaluate(data_gen.valid)\n",
    "performance['Multi step dense'] = multi_step_dense.evaluate(data_gen.test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try an RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    layers.LSTM(32, return_sequences=True),\n",
    "    layers.LSTM(32),\n",
    "    # Shape => [batch, time, features]\n",
    "    # layers.TimeDistributed(layers.Dense(units=3, activation='softmax'))\n",
    "    layers.Dense(units=3, activation='softmax'),\n",
    "    layers.Reshape([1, -1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "504/504 [==============================] - 9s 12ms/step - loss: 1.0133 - accuracy: 0.5026 - val_loss: 1.0715 - val_accuracy: 0.4045\n",
      "Epoch 2/10\n",
      "504/504 [==============================] - 5s 10ms/step - loss: 0.9813 - accuracy: 0.5182 - val_loss: 1.0585 - val_accuracy: 0.4265\n",
      "Epoch 3/10\n",
      "504/504 [==============================] - 5s 10ms/step - loss: 0.9727 - accuracy: 0.5235 - val_loss: 1.0524 - val_accuracy: 0.4403\n",
      "Epoch 4/10\n",
      "504/504 [==============================] - 5s 10ms/step - loss: 0.9665 - accuracy: 0.5237 - val_loss: 1.0483 - val_accuracy: 0.4462\n",
      "Epoch 5/10\n",
      "504/504 [==============================] - 5s 11ms/step - loss: 0.9610 - accuracy: 0.5241 - val_loss: 1.0454 - val_accuracy: 0.4500\n",
      "Epoch 6/10\n",
      "504/504 [==============================] - 5s 11ms/step - loss: 0.9559 - accuracy: 0.5235 - val_loss: 1.0435 - val_accuracy: 0.4531\n",
      "Epoch 7/10\n",
      "504/504 [==============================] - 5s 10ms/step - loss: 0.9513 - accuracy: 0.5247 - val_loss: 1.0420 - val_accuracy: 0.4521\n",
      "Epoch 8/10\n",
      "504/504 [==============================] - 5s 11ms/step - loss: 0.9476 - accuracy: 0.5257 - val_loss: 1.0407 - val_accuracy: 0.4535\n",
      "Epoch 9/10\n",
      "504/504 [==============================] - 5s 10ms/step - loss: 0.9446 - accuracy: 0.5275 - val_loss: 1.0393 - val_accuracy: 0.4536\n",
      "Epoch 10/10\n",
      "504/504 [==============================] - 5s 10ms/step - loss: 0.9421 - accuracy: 0.5289 - val_loss: 1.0376 - val_accuracy: 0.4554\n",
      "289/289 [==============================] - 1s 4ms/step - loss: 1.0376 - accuracy: 0.4554\n"
     ]
    }
   ],
   "source": [
    "history = compile_and_fit(lstm_model, data_gen, patience=5, max_epochs=10)\n",
    "\n",
    "val_performance['LSTM'] = lstm_model.evaluate(data_gen.valid)\n",
    "performance['LSTM'] = lstm_model.evaluate(data_gen.test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a Transformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def transformer_encoder(inputs, n_heads, d_k, d_v, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        num_heads=n_heads, key_dim=d_k, value_dim=d_v, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "\n",
    "def build_model(\n",
    "            input_shape,\n",
    "            n_heads,\n",
    "            d_k,\n",
    "            d_v,\n",
    "            ff_dim,\n",
    "            num_transformer_blocks,\n",
    "            mlp_units,\n",
    "            n_outputs=1,\n",
    "            dropout=0.1,\n",
    "            mlp_dropout=0.1,\n",
    "        ):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, n_heads, d_k, d_v, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(n_outputs, activation='softmax')(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = inputs.shape[1:]\n",
    "\n",
    "xformer_model = build_model(\n",
    "    input_shape,\n",
    "    n_heads=4,\n",
    "    d_k=512,\n",
    "    d_v=512,\n",
    "    ff_dim=256,\n",
    "    num_transformer_blocks=2,\n",
    "    mlp_units=[256],\n",
    "    n_outputs=3,\n",
    "    dropout=0.1,\n",
    "    mlp_dropout=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "504/504 [==============================] - 12s 20ms/step - loss: 0.9909 - accuracy: 0.5007 - val_loss: 1.0561 - val_accuracy: 0.4590\n",
      "Epoch 2/10\n",
      "504/504 [==============================] - 10s 19ms/step - loss: 0.9666 - accuracy: 0.5152 - val_loss: 1.0449 - val_accuracy: 0.4625\n",
      "Epoch 3/10\n",
      "504/504 [==============================] - 10s 19ms/step - loss: 0.9515 - accuracy: 0.5283 - val_loss: 1.0286 - val_accuracy: 0.4673\n",
      "Epoch 4/10\n",
      "504/504 [==============================] - 10s 19ms/step - loss: 0.9434 - accuracy: 0.5329 - val_loss: 1.0368 - val_accuracy: 0.4664\n",
      "Epoch 5/10\n",
      "504/504 [==============================] - 10s 19ms/step - loss: 0.9391 - accuracy: 0.5336 - val_loss: 1.0314 - val_accuracy: 0.4692\n",
      "Epoch 6/10\n",
      "504/504 [==============================] - 10s 19ms/step - loss: 0.9371 - accuracy: 0.5345 - val_loss: 1.0322 - val_accuracy: 0.4696\n",
      "Epoch 7/10\n",
      "504/504 [==============================] - 10s 19ms/step - loss: 0.9330 - accuracy: 0.5369 - val_loss: 1.0342 - val_accuracy: 0.4660\n",
      "Epoch 8/10\n",
      "504/504 [==============================] - 10s 19ms/step - loss: 0.9315 - accuracy: 0.5386 - val_loss: 1.0369 - val_accuracy: 0.4646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19c56807490>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compile_and_fit(xformer_model, data_gen, lr=1e-3, patience=5, max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 3s 9ms/step - loss: 1.0006 - accuracy: 0.4758\n"
     ]
    }
   ],
   "source": [
    "val_performance['xformer'] = xformer_model.evaluate(data_gen.valid)\n",
    "performance['xfomrer'] = xformer_model.evaluate(data_gen.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Baseline': [nan, 0.40911057591438293],\n",
       " 'Multi step dense': [1.0593593120574951, 0.46257176995277405],\n",
       " 'Dense': [1.0622918605804443, 0.4489288032054901],\n",
       " 'LSTM': [1.0376485586166382, 0.45542195439338684],\n",
       " 'xformer': [1.0005801916122437, 0.4757881164550781]}"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to determine how well the model predicts the upcoming price movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = tf.squeeze(xformer_model(inputs))\n",
    "y = tf.squeeze(targets)\n",
    "\n",
    "true_moves = np.ones_like(y.numpy())\n",
    "true_moves[y > 0.1] = 2\n",
    "true_moves[y < -0.1] = 0\n",
    "\n",
    "pred_moves = np.ones_like(yhat.numpy())\n",
    "pred_moves[yhat > 0.1] = 2\n",
    "pred_moves[yhat < -0.1] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_moves = tf.convert_to_tensor(true_moves)\n",
    "pred_moves = tf.convert_to_tensor(pred_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 2., 2., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.boolean_mask(tmp, tf.greater(y, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_movement_loss(y, yhat, thresh=0.1):\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b2da39daaaff30a84159e8452ba91acfc0bbd521fb66c6aa9941f847b87bd81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
